# probe_fusion_chain.py
# ç›®çš„ï¼šæ‰‹åŠ¨æŒ‡å®šè¾“å…¥ï¼ˆé—®é¢˜ç»´åº¦ã€èåˆé“¾ã€æ˜ å°„ã€è¾¹ç•Œæ¦‚ç‡/Logit ç­‰ï¼‰ï¼Œåªåšä¸€æ¬¡å‰å‘ï¼Œè¾“å‡ºå¯å¯¹æ ‡çš„ç»†ç²’åº¦ç»Ÿè®¡ã€‚
import math
import json
import argparse
from typing import Dict, List, Any, Optional

import torch
import torch.nn as nn

# ===== æŒ‰ä½ çš„é¡¹ç›®ç»“æ„å¯¼å…¥ =====
from dosa.config import Config
from dosa.hardware_parameters import HardwareParameters
from dosa.mapping import FineGrainedMapping
from dosa.performance_model import HighFidelityPerformanceModel

# =============== 1) è¾“å…¥è§„èŒƒ ===============
# è¯´æ˜ï¼šä½ å¯ç”¨å‘½ä»¤è¡Œ --input æŒ‡å®š JSONï¼›è‹¥ä¸æŒ‡å®šï¼Œåˆ™ä½¿ç”¨ä¸‹æ–¹ INPUT_SPECã€‚
# æ³¨æ„ï¼šè¿™é‡Œä¸æ”¾å…·ä½“æ•°å€¼æ ·ä¾‹ï¼Œä»¥å…å¹²æ‰°ä½ è‡ªå·±çš„ Golden é…ç½®ï¼›ä»…ç»™å‡ºå­—æ®µç»“æ„ã€‚
INPUT_SPEC = {
    "device": "cuda",                # ç”¨GPU
    "problem_dims": {                # å…¨å±€é—®é¢˜ç»´åº¦ï¼ˆè¿™é‡Œåªæ˜¯baselineï¼Œå¯æŒ‰layerè¦†ç›–ï¼‰
        "N": 1,
        "C": 64,
        "K": 256,
        "P": 32,
        "Q": 32,
        "R": 3,
        "S": 3
    },
    "hardware": {                    # ç¡¬ä»¶é…ç½®
        "initial_num_pes": 64,
        "initial_l0_kb": 2,
        "initial_l1_kb": 4,
        "initial_l2_kb": 64
    },
    "graph": {
        "layers": [
            {
                "name": "conv1",
                "type": "Conv",
                "dims": {"N":1, "C":3, "K":16, "P":32, "Q":32, "R":3, "S":3}
            },
            {
                "name": "conv2",
                "type": "Conv",
                "dims": {"N":1, "C":16, "K":32, "P":32, "Q":32, "R":3, "S":3}
            }
        ],
        "fusion_groups": [
            ["conv1","conv2"]
        ],
        "layer_order": [
            "input","conv1","conv2","output"
        ]
    },
    "mappings": {
  "conv1": {
    "discrete_factors": {
      "L0_Registers": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 1,
          "S": 1,
          "K": 1,
          "C": 1,
          "N": 1
        },
        "spatial": {
          "K": 4,
          "C": 3
        }
      },
      "L1_Accumulator": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 3,
          "S": 3,
          "K": 1,
          "C": 1,
          "N": 1
        }
      },
      "L2_Scratchpad": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 1,
          "S": 1,
          "K": 1,
          "C": 1,
          "N": 1
        }
      }
    }
  },
  "conv2": {
    "discrete_factors": {
      "L0_Registers": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 1,
          "S": 1,
          "K": 1,
          "C": 1,
          "N": 1
        },
        "spatial": {
          "K": 8,
          "C": 4
        }
      },
      "L1_Accumulator": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 3,
          "S": 3,
          "K": 1,
          "C": 1,
          "N": 1
        }
      },
      "L2_Scratchpad": {
        "temporal": {
          "P": 1,
          "Q": 1,
          "R": 1,
          "S": 1,
          "K": 1,
          "C": 1,
          "N": 1
        }
      }
    }
  }
},
    "fusion_boundaries": {
        "conv1->conv2": {"s": 0.99},
        "conv2->conv3": {"s": 0.99}
    },
    "print_options": {
        "show_lb": True,
        "show_per_layer_traffic": True,
        "show_group_counters": True
    }
}


# =============== 2) å®ç”¨å‡½æ•°ï¼ˆæ„å»ºå›¾ / è®¾ç½®å‚æ•° / æ‰“å°ï¼‰ ===============
def _safe_ln(x: float) -> float:
    if x is None:
        raise ValueError("ç¦»æ•£ factor ç¼ºå¤±å…·ä½“å€¼")
    if x <= 0:
        raise ValueError(f"ç¦»æ•£ factor å¿…é¡» > 0ï¼Œæ”¶åˆ° {x}")
    return math.log(float(x))

def build_graph_from_spec(spec: Dict[str, Any]):
    """æŒ‰ spec æ„å»ºä¸€ä¸ªç®€å•å›¾å¯¹è±¡ï¼›åªè¦å­—æ®µå¥‘åˆä½ ç°æœ‰ HighFidelityPerformanceModel çš„éœ€æ±‚å³å¯ã€‚"""
    dims_global = spec["problem_dims"]
    gspec = spec["graph"]
    # è¿™é‡Œç”¨æœ€å°å®ç°ï¼ˆè½»é‡ Mockï¼‰ï¼Œä¸ä½ å·¥ç¨‹ä¸­ evaluate_* çš„æ¥å£å­—æ®µä¿æŒä¸€è‡´
    class G:
        def __init__(self, dims, gspec):
            self.problem_dims = dims
            self.layers = {}
            # å¯é€‰è‡ªåŠ¨è¡¥ input/output
            if "layer_order" in gspec:
                self.layer_order = gspec["layer_order"]
            else:
                self.layer_order = [x["name"] for x in gspec["layers"]]

            for info in gspec["layers"]:
                name = info["name"]
                ltype = info.get("type", "Conv")
                ldims = info.get("dims", dims)  # è‹¥å•å±‚è¦†ç›– dims
                # çº¦å®š Conv çš„ shape å­—æ®µï¼ˆä¸ä½ å·¥ç¨‹ä¸€è‡´å³å¯ï¼‰
                node = {"type": ltype, "dims": ldims}
                if ltype == "Conv":
                    node["input_shape"]  = [ldims["N"], ldims["C"], ldims["P"]+ldims["R"]-1, ldims["Q"]+ldims["S"]-1]
                    node["output_shape"] = [ldims["N"], ldims["K"], ldims["P"], ldims["Q"]]
                    node["weight_shape"] = [ldims["K"], ldims["C"], ldims["R"], ldims["S"]]
                self.layers[name] = node

            self.fusion_groups = gspec["fusion_groups"]
            self.adjacency = {}  # å¦‚æœä½ çš„å®ç°ç”¨åˆ°ï¼Œå¯åœ¨æ­¤æ„é€ 
    return G(dims_global, gspec)

def create_mapping_for_layer(layer_dims: Dict[str, int], mem_hierarchy) -> FineGrainedMapping:
    m = FineGrainedMapping(layer_dims, mem_hierarchy)
    # é»˜è®¤ç»™ä¸ªç¨³å®šåˆå§‹åŒ–ï¼ˆä¸ä¼šä¼˜åŒ–ï¼Œæ‰€ä»¥åªä¸ºé¿å…å¥‡å¼‚å€¼ï¼‰
    for i, p in enumerate(m.parameters()):
        p.data.fill_(1.0 if i != 1 else 2.0)
    return m

def apply_log_params(mapping: FineGrainedMapping, log_param_dict: Dict[str, float]):
    """æ–¹å¼ Aï¼šç›´æ¥æŠŠ log-param åå­—ç²¾ç¡®å†™è¿›æ¥ï¼ˆä¸ named_parameters å¯¹é½ï¼‰"""
    named = dict(mapping.named_parameters())
    for k, v in log_param_dict.items():
        if k not in named:
            raise KeyError(f"æœªæ‰¾åˆ°æ˜ å°„å‚æ•°: {k}")
        named[k].data.fill_(float(v))

def apply_discrete_factors(mapping: FineGrainedMapping, disc: Dict[str, Any]):
    """
    æ–¹å¼ Bï¼šç»™å‡ºæ¯å±‚çº§/temporal|spatial/ç»´åº¦çš„ç¦»æ•£å€¼ï¼Œè„šæœ¬è‡ªåŠ¨å›å¡« log=ln(value)
    çº¦æŸï¼šå€¼å¿…é¡» > 0ï¼›æœªç»™åˆ°çš„é¡¹ä¸æ”¹åŠ¨ã€‚
    """
    named = dict(mapping.named_parameters())
    # ä½ çš„ FineGrainedMapping çš„å‘½åè§„åˆ™æŒ‰ä½ å‘æ¥çš„é£æ ¼ï¼š<level>.<dim>.<temporal|spatial>
    # æˆ‘ä»¬åœ¨æ­¤æŒ‰ç…§ disc ç»“æ„æ‹¼æ¥é”®åå¹¶å†™å…¥ ln(value)
    for level, tmap in disc.items():  # e.g. "L2_Scratchpad": {"temporal":{"K":4,...}, "spatial":{"P":1,...}}
        for kind in ("temporal", "spatial"):
            if kind not in tmap: 
                continue
            for dim, val in tmap[kind].items():
                key = f"factors.{level}.{dim}.{kind}"
                if key not in named:
                    # æœ‰çš„å®ç°ç”¨ <level>.<dim>.temporal ç­‰åœ¨ä¸€ä¸ªå‘½åç©ºé—´ï¼›æœ‰çš„ä»¥ç¨å¼‚åã€‚å¿…è¦æ—¶ä½ åœ¨æ­¤å¯¹é½ä¸€ä¸‹
                    raise KeyError(f"æœªæ‰¾åˆ°æ˜ å°„å‚æ•°: {key}")
                named[key].data.fill_(_safe_ln(val))

def build_layer_mappings(spec: Dict[str, Any], graph) -> Dict[str, FineGrainedMapping]:
    layer2mapping = {}
    for lname, node in graph.layers.items():
        if node["type"] != "Conv":
            continue
        m = create_mapping_for_layer(node["dims"], Config.get_instance().MEMORY_HIERARCHY)
        user = spec["mappings"].get(lname, {})
        if "log_params" in user and user["log_params"]:
            apply_log_params(m, user["log_params"])
        if "discrete_factors" in user and user["discrete_factors"]:
            apply_discrete_factors(m, user["discrete_factors"])
        layer2mapping[lname] = m
    return layer2mapping

def set_fusion_boundaries(perf: HighFidelityPerformanceModel, group_layers: List[str], fb: Dict[str, Any]):
    # ç¡®ä¿åˆå§‹åŒ–è¿‡è¾¹ç•Œå‚æ•°ï¼ˆè‹¥ä½ çš„æ¨¡å‹æ–¹æ³•åä¸åŒï¼Œè¯·æ›¿æ¢ï¼‰
    perf.init_fusion_boundaries(group_layers)
    for i in range(len(group_layers)-1):
        key = f"{group_layers[i]}->{group_layers[i+1]}"
        if key not in fb:
            continue
        item = fb[key]
        if "logit" in item and item["logit"] is not None:
            perf.fusion_boundary_logits[key].data.fill_(float(item["logit"]))
        elif "s" in item and item["s"] is not None:
            s = float(item["s"])
            # clip é¿å… inf
            s = min(max(s, 1e-6), 1-1e-6)
            logit = math.log(s/(1.0-s))
            perf.fusion_boundary_logits[key].data.fill_(logit)

def tensor_to_float(x: Any) -> Any:
    if isinstance(x, torch.Tensor):
        return float(x.item())
    if isinstance(x, dict):
        return {k: tensor_to_float(v) for k, v in x.items()}
    if isinstance(x, list):
        return [tensor_to_float(v) for v in x]
    return x

def run_single_forward(spec: Dict[str, Any]) -> Dict[str, Any]:
    # =============== é…ç½® ===============
    cfg = Config.get_instance()
    if spec.get("device"):
        cfg.DEVICE = spec["device"]

    perf = HighFidelityPerformanceModel(cfg)

    # =============== ç¡¬ä»¶å‚æ•° ===============
    h = spec["hardware"]
    hw = HardwareParameters(
        initial_num_pes=float(h["initial_num_pes"]),
        initial_l0_kb=float(h["initial_l0_kb"]),
        initial_l1_kb=float(h["initial_l1_kb"]),
        initial_l2_kb=float(h["initial_l2_kb"])
    )

    # =============== å›¾ä¸èåˆé“¾ ===============
    graph = build_graph_from_spec(spec)
    if not spec["graph"]["fusion_groups"]:
        raise ValueError("fusion_groups ä¸ºç©º")
    group = spec["graph"]["fusion_groups"][0]  # åªç”¨ç¬¬ä¸€æ¡é“¾

    # =============== per-layer æ˜ å°„ & èåˆè¾¹ç•Œå‚æ•° ===============
    layer2mapping = build_layer_mappings(spec, graph)
    set_fusion_boundaries(perf, group, spec.get("fusion_boundaries", {}))

    # =============== å‰å‘æ‰§è¡Œ ===============
    with torch.no_grad():
        # forward æ¥å£è¿”å›æ›´å®Œæ•´çš„æŒ‡æ ‡
        latency, energy, area, mismatch, compat, invalid_penalty, penalty = perf(
            graph=graph,
            hw_params=hw,
            layer2mapping=layer2mapping,
            fusion_params=None
        )

    # =============== ç»“æœç»“æ„åŒ– ===============
    out: Dict[str, Any] = {
        "fusion_group": group,
        "fusion_boundaries": [
            {
                "key": f"{group[i]}->{group[i+1]}",
                "logit": float(perf.fusion_boundary_logits[f"{group[i]}->{group[i+1]}"].item()),
                "s": float(torch.sigmoid(perf.fusion_boundary_logits[f"{group[i]}->{group[i+1]}"]).item())
            }
            for i in range(len(group)-1)
        ],
        "chain_metrics": {
            "latency": float(latency.item()),
            "energy":  float(energy.item()),
            "area":    float(area.item()),
            "mismatch_loss": float(mismatch.item()) if isinstance(mismatch, torch.Tensor) else float(mismatch),
            "compat": float(compat.item()) if isinstance(compat, torch.Tensor) else float(compat),
            "mapping_invalid_penalty": float(invalid_penalty),
            "penalty": float(penalty.item())
        }
    }

    return out

# =============== 4) äººç±»å¯è¯»æ‰“å° ===============
def pretty_print(out: Dict[str, Any], spec: Dict[str, Any]):
    print("\n" + "="*80)
    print("ğŸ”— Fusion Boundaries")
    for b in out.get("fusion_boundaries", []):
        print(f"  {b['key']:>20s}  logit={b['logit']:+.6f}  s={b['s']:.6f}")

    print("\n" + "="*80)
    print("ğŸ“Š Chain-level Metrics")
    cm = out.get("chain_metrics", {})
    print(f"  Latency={cm.get('latency', 0.0):.6e}  Energy={cm.get('energy', 0.0):.6e}  Area={cm.get('area', 0.0):.6e}")
    print(f"  mismatch={cm.get('mismatch_loss', 0.0):.6e}  compat={cm.get('compat', 0.0):.6e}")
    print(f"  invalid_penalty={cm.get('mapping_invalid_penalty', 0.0):.6e}  penalty={cm.get('penalty', 0.0):.6e}")

    if spec.get("print_options", {}).get("show_group_counters", True):
        gr = out.get("group_counters", {
            "L3_service_bytes": 0.0,
            "L2_service_bytes": 0.0,
            "W_L2_to_L0_bytes": 0.0
        })
        print("\n" + "="*80)
        print("ğŸ“¦ Group Counters")
        print(f"  L3_service_bytes : {gr['L3_service_bytes']:.6e}")
        print(f"  L2_service_bytes : {gr['L2_service_bytes']:.6e}")
        print(f"  W(L2->L0)_bytes  : {gr['W_L2_to_L0_bytes']:.6e}")

    if spec.get("print_options", {}).get("show_per_layer_traffic", True) and "layers" in out:
        print("\n" + "="*80)
        print("ğŸ§¾ Per-layer Traffic (reads/writes/updates)")
        for L in out.get("layers", []):
            print(f"\nâ€” {L['name']}")
            for cat in ("reads","writes","updates"):
                m = L.get(cat, {})
                if not m:
                    print(f"  {cat}: (none)")
                    continue
                print(f"  {cat}:")
                for lvl, kv in m.items():
                    total = sum(kv.values())
                    w = kv.get("Weight", 0.0); i = kv.get("Input", 0.0); o = kv.get("Output", 0.0)
                    print(f"    {lvl:<16s} total={total:.3e}  [W={w:.3e} I={i:.3e} O={o:.3e}]")
            print(f"  L3_service={L.get('L3_service_bytes',0.0):.3e} | "
                  f"L2_service={L.get('L2_service_bytes',0.0):.3e} | "
                  f"W(L2->L0)={L.get('W_L2_to_L0_bytes',0.0):.3e}")

# =============== 5) CLI ===============
def main():
    parser = argparse.ArgumentParser(description="Fusion Chain Probe (No-Optimize, Single Forward)")
    parser.add_argument("--input", type=str, default=None, help="JSON spec file (same schema as INPUT_SPEC)")
    parser.add_argument("--output", type=str, default=None, help="Save outputs as JSON")
    args = parser.parse_args()

    if args.input:
        with open(args.input, "r", encoding="utf-8") as f:
            spec = json.load(f)
    else:
        spec = INPUT_SPEC

    out = run_single_forward(spec)
    pretty_print(out, spec)

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(out, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… å·²å†™å…¥è¾“å‡ºåˆ°: {args.output}")

if __name__ == "__main__":
    torch.set_printoptions(sci_mode=True, precision=6)
    main()
