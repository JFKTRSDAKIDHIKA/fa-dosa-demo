from abc import ABC, abstractmethod
import torch
import torch.optim as optim
import numpy as np
from typing import Dict, Any, List, Tuple
import random
from .utils import OptimizationLogger, get_divisors, derive_minimal_hardware
from .space import SearchSpace

# ==== DEBUG UTIL BEGIN ====
import math, hashlib, io, torch, inspect
from pprint import pformat

def _hash_state_dict(sd):
    # å¯¹ state_dict åšç¨³å®š hashï¼Œæ–¹ä¾¿å¯¹æ¯”æ˜¯å¦"çœŸçš„å˜äº†"
    h = hashlib.sha1()
    for k in sorted(sd.keys()):
        v = sd[k]
        if torch.is_tensor(v):
            h.update(k.encode())
            h.update(v.detach().cpu().numpy().tobytes())
        else:
            h.update((k + str(v)).encode())
    return h.hexdigest()[:10]

def _dump_mapping_raw(mapping, tag="[RAW]"):
    # æ‰“å° log-space å‚æ•° -> exp åçš„çœŸå®å› å­ï¼ˆä¸åšæŠ•å½±ï¼‰
    try:
        print(f"{tag} mapping raw (exp(log)): hash={_hash_state_dict(mapping.state_dict())}")
        for lvl in ["L0_Registers","L1_Accumulator","L2_Scratchpad","L3_DRAM"]:
            if lvl not in mapping.factors:
                continue
            row = []
            for dim in ["N","C","K","P","Q","R","S"]:
                try:
                    t = mapping.factors[lvl][dim]["temporal"]
                    s = mapping.factors[lvl][dim]["spatial"]
                    t_val = float(torch.exp(t).detach().cpu()) if torch.is_tensor(t) else float(t)
                    s_val = float(torch.exp(s).detach().cpu()) if torch.is_tensor(s) else float(s)
                    row.append(f"{dim}:T={t_val:.2f},S={s_val:.2f}")
                except Exception:
                    pass
            if row:
                print(f"{tag} {lvl}: " + " | ".join(row))
    except Exception as e:
        print(f"{tag} dump raw failed: {e}")

def _dump_mapping_projected(mapping, tag="[PROJ]"):
    # æ‰“å° snapshot / projected å› å­ï¼ˆä½ çš„ _snapshot_mapping ç”¨çš„å°±æ˜¯è¿™ä¸ªå£å¾„ï¼‰
    try:
        if hasattr(mapping, "get_projected_factors"):
            proj = mapping.get_projected_factors()
        elif hasattr(mapping, "get_all_factors"):
            proj = mapping.get_all_factors()  # æœ‰äº›å®ç°æŠŠå®ƒå°±å½“ projected ç”¨
        else:
            print(f"{tag} no projected getter on mapping"); return
        print(f"{tag} projected mapping:\n" + pformat(proj)[:3000])
        return proj
    except Exception as e:
        print(f"{tag} dump projected failed: {e}")

def _print_requires_grad_flags(searcher, tag="[FLAGS]"):
    m_on = sum(1 for p in searcher.mapping.parameters() if p.requires_grad)
    f_on = sum(1 for p in searcher.fusion_params.parameters() if p.requires_grad)
    h_on = sum(1 for p in searcher.hw_params.parameters() if p.requires_grad)
    print(f"{tag} requires_grad -> mapping:{m_on} on | fusion:{f_on} on | hardware:{h_on} on")
# ==== DEBUG UTIL END ====

# ===== Frozen proxy & perf-model wrapper (lock discrete mapping) =====
class _FrozenMappingProxy:
    """Wrap mapping and force get_all_factors() to return a frozen snapshot."""
    def __init__(self, mapping, frozen_factors):
        self._mapping = mapping
        self._frozen = self._deep_clone_factors(frozen_factors)

    def _deep_clone_factors(self, factors):
        """Deep clone factors dict, handling PyTorch tensors properly"""
        if isinstance(factors, torch.Tensor):
            return factors.detach().clone()
        elif isinstance(factors, dict):
            return {k: self._deep_clone_factors(v) for k, v in factors.items()}
        elif isinstance(factors, (list, tuple)):
            return type(factors)(self._deep_clone_factors(item) for item in factors)
        else:
            return factors

    def get_all_factors(self, *args, **kwargs):
        return self._deep_clone_factors(self._frozen)

    def __getattr__(self, name):
        return getattr(self._mapping, name)


class _PerfModelWrapper:
    """
    Transparent wrapper for perf_model:
    - Phase A: sample once from mapping, remember it on searcher, and evaluate with a frozen proxy.
    - Phase B: always replace mapping with searcher.best_discrete_factors (frozen).
    """
    def __init__(self, searcher, inner_callable):
        self._searcher = searcher
        self._inner = inner_callable

    def __call__(self, graph, hw_params, mapping, fusion_params):
        # Phase B: use frozen best
        if getattr(self._searcher, "_freeze_discrete", False) and (self._searcher.best_discrete_factors is not None):
            mapping = _FrozenMappingProxy(mapping, self._searcher.best_discrete_factors)
            return self._inner(graph, hw_params, mapping, fusion_params)

        # Phase A: sample once -> remember -> freeze for this call
        # ğŸ› ï¸ 5. åœ¨ perf_model é‡Œæ’æ¡© - æ£€æŸ¥æŠ•å½±å‰åçš„grad_fn
        if hasattr(mapping, 'factors') and mapping.factors:
            # è·å–ç¬¬ä¸€ä¸ªmappingå‚æ•°ä½œä¸ºç¤ºä¾‹
            first_level = next(iter(mapping.factors.keys()))
            first_dim = next(iter(mapping.factors[first_level].keys()))
            raw_param = mapping.factors[first_level][first_dim]['temporal']
            print(f"[DEBUG] mapping raw param grad_fn: {raw_param.grad_fn}")
        
        # æŠŠ log-space çš„è¿ç»­å‚æ•° temporal, spatial è½¬æ¢æˆçœŸæ­£çš„æ•´æ•°åˆ†å—å› å­ï¼ˆdiscrete factorsï¼‰ã€‚
        sampled = mapping.get_all_factors()
        
        # æ£€æŸ¥æŠ•å½±åçš„grad_fn
        if sampled:
            first_dim_key = next(iter(sampled.keys()))
            first_level_key = next(iter(sampled[first_dim_key].keys()))
            projected_tensor = sampled[first_dim_key][first_level_key]['temporal']
            print(f"[DEBUG] mapping projected grad_fn: {projected_tensor.grad_fn}")
        
        self._searcher._last_eval_discrete_factors = sampled
        # ğŸ› ï¸ "å¼€å…³å¼æ¶ˆè" - å…³é—­Phase-Açš„Frozen/Proxyæœºåˆ¶
        # mapping = _FrozenMappingProxy(mapping, sampled)  # <- Phase-Aä¸å†ä½¿ç”¨frozenå¿«ç…§
        # Phase-Aç›´æ¥ä½¿ç”¨åŸå§‹mappingå¯¹è±¡ï¼Œä¿æŒæ¢¯åº¦è¿é€šæ€§
        latency, energy, area, mismatch, compat = self._inner(graph, hw_params, mapping, fusion_params)
        for name, t in [("latency", latency), ("energy", energy), ("area", area), ("mismatch", mismatch), ("compat", compat)]:
            print(f"[CHECK inner out] {name}: type={type(t)}, req_grad={getattr(t, 'requires_grad', None)}, grad_fn={getattr(t, 'grad_fn', None)}")

        return latency, energy, area, mismatch, compat



class BaseSearcher(ABC):
    """æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰æ‰€æœ‰æœç´¢å™¨çš„é€šç”¨æ¥å£"""
    
    def __init__(self, graph, hw_params, mapping, fusion_params, perf_model, config, logger=None, recorder=None):
        """
        åˆå§‹åŒ–æœç´¢å™¨
        
        Args:
            graph: ComputationGraphå®ä¾‹
            hw_params: HardwareParameterså®ä¾‹
            mapping: FineGrainedMappingå®ä¾‹
            fusion_params: FusionParameterså®ä¾‹
            perf_model: HighFidelityPerformanceModelå®ä¾‹
            config: é…ç½®å¯¹è±¡
            logger: StructuredLoggerå®ä¾‹
        """
        self.graph = graph
        self.hw_params = hw_params
        # Number of PEs is now derived from ``min_hw`` and kept fixed during
        # optimization. Disable gradient updates for this parameter to avoid
        # treating it as a learnable variable.
        self.hw_params.log_num_pes.requires_grad = False
        self.mapping = mapping
        self.fusion_params = fusion_params
        self._orig_perf_model = perf_model
        self.perf_model = _PerfModelWrapper(self, perf_model)

        self.config = config
        self.logger = logger
        # ä¸»è°ƒç”¨æ–¹å¯é€‰åœ°ä¼ å…¥ Recorderï¼Œç”¨äºè®°å½•æ¯ä¸€æ­¥è¯•éªŒä¿¡æ¯å’Œæœ€ä½³ç»“æœ
        self.recorder = recorder
        
        # åˆ›å»ºæœç´¢ç©ºé—´å®ä¾‹
        self.space = SearchSpace(graph)
        
        # è®°å½•æœ€ä½³ç»“æœ
        # - ``best_loss``/``best_params``/``best_metrics`` ä¿ç•™åŸºäºæŸå¤±çš„æœ€ä¼˜è®°å½•ï¼Œ
        #   ä»¥ä¾¿ç»§ç»­ä¾èµ–è´¨é‡é©±åŠ¨è§¦å‘å™¨ç­‰é€»è¾‘ã€‚
        # - ``best_edp`` åŠå…¶ç›¸å…³å­—æ®µå•ç‹¬è·Ÿè¸ª EDP æœ€ä¼˜é…ç½®ï¼Œ
        #   ä¾› PhaseB ç»§ç»­ä¼˜åŒ–ä»¥åŠæœ€ç»ˆç»“æœæŠ¥å‘Šä½¿ç”¨ã€‚
        self.best_loss = float('inf')
        self.best_params = None
        self.best_metrics = None
        self.best_edp = float('inf')
        self.best_edp_params = None
        self.best_edp_metrics = None

        # Scheme-B snapshots / switch
        self._last_eval_discrete_factors: Optional[Dict[str, any]] = None
        self.best_discrete_factors: Optional[Dict[str, any]] = None
        self._freeze_discrete: bool = False

        
        # æŸå¤±ç­–ç•¥é…ç½®
        self.loss_strategy = getattr(config, 'LOSS_STRATEGY', 'log_edp_plus_area')
        self.loss_weights = getattr(config, 'LOSS_WEIGHTS', {
            'area_weight': getattr(config, 'AREA_WEIGHT', 0.1),
            'mismatch_penalty_weight': getattr(config, 'MISMATCH_PENALTY_WEIGHT', 0.1),
            'compatibility_penalty_weight': getattr(config, 'COMPATIBILITY_PENALTY_WEIGHT', 100.0),
            'edp_weight': 1.0
        })
        
        # ç”¨äºå¯è§†åŒ–çš„å†å²æ•°æ®å­˜å‚¨
        self.loss_history = []  # å­˜å‚¨æ¯æ­¥çš„losså€¼
        self.grad_norm_history = []  # å­˜å‚¨æ¯æ­¥çš„æ¢¯åº¦èŒƒæ•°
        self.step_history = []  # å­˜å‚¨æ­¥æ•°
        self.phase_history = []  # å­˜å‚¨é˜¶æ®µä¿¡æ¯ ('A' æˆ– 'B')
        self.param_history = []  # å­˜å‚¨å‚æ•°å†å²ï¼Œç”¨äºçƒ­åŠ›å›¾
    
    @abstractmethod
    def search(self, num_trials: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢ç®—æ³•
        
        Args:
            num_trials: è¯„ä¼°æ¬¡æ•°
            
        Returns:
            åŒ…å«æœ€ä½³ç»“æœçš„å­—å…¸
        """
        pass
    
    def evaluate(self, flat_params: List[float]) -> Tuple[float, Dict[str, float]]:
        """
        ç»Ÿä¸€çš„ç›®æ ‡å‡½æ•°æ¥å£ï¼Œè¯„ä¼°ç»™å®šå‚æ•°çš„æ€§èƒ½
        
        Args:
            flat_params: æ‰å¹³åŒ–çš„å‚æ•°åˆ—è¡¨
            
        Returns:
            (loss, metrics): æŸå¤±å€¼å’Œæ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        # å°†æ‰å¹³åŒ–å‚æ•°è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸
        params_dict = self.space.from_flat(flat_params)
        
        # å°†å‚æ•°è®¾ç½®åˆ°æ¨¡å‹ä¸­
        self._set_params_from_dict(params_dict)

        # Derive minimal hardware and fix the number of PEs accordingly.
        # The PE count is treated as a deterministic value from ``min_hw``
        # instead of a differentiable parameter.
        min_hw = derive_minimal_hardware(self.mapping, self.config)
        if getattr(self.config, "APPLY_MIN_HW_BOUNDS", True):
            self._apply_min_hw_bounds(min_hw, reset=False)
        else:
            print("[DEBUG] Skipping minimal hardware bounds in evaluation")

        # è°ƒç”¨æ€§èƒ½æ¨¡å‹
        latency, energy, area, mismatch_loss, compatibility_penalty = self.perf_model(
            self.graph, self.hw_params, self.mapping, self.fusion_params
        )

        if self.logger is not None:
            self.logger.event(
                "fusion_decisions",
                decisions=self.fusion_params.get_fusion_decisions_serializable(self.graph),
            )
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—æ–¹æ³•
        loss = self._compute_loss(latency, energy, area, mismatch_loss, compatibility_penalty)
        
        # æ„å»ºæ€§èƒ½æŒ‡æ ‡å­—å…¸
        metrics = {
            'latency_sec': latency.item(),
            'energy_pj': energy.item(),
            'area_mm2': area.item(),
            'edp': (latency * energy).item(),
            'log_edp': (torch.log(latency + 1e-9) + torch.log(energy + 1e-9)).item(),
            'mismatch_loss': mismatch_loss.item()
        }
        
        # å­˜å‚¨loss breakdownç”¨äºåç»­çš„update_best_resultè°ƒç”¨
        self._last_loss_breakdown = self._compute_loss_breakdown(latency, energy, area, mismatch_loss, compatibility_penalty, step_count=0)
        
        return loss.item(), metrics
    
    def _compute_loss(self, latency, energy, area, mismatch_loss, compatibility_penalty, step_count=0):
        """
        è®¡ç®—æ€»æŸå¤± - å®Œæ•´å¤ç°åŸå§‹run.pyä¸­çš„æŸå¤±è®¡ç®—é€»è¾‘ï¼Œå¹¶é›†æˆé¢ç§¯é¢„ç®—æƒ©ç½šé¡¹
        
        Args:
            latency: å»¶è¿Ÿå¼ é‡
            energy: èƒ½è€—å¼ é‡
            area: é¢ç§¯å¼ é‡
            mismatch_loss: ä¸åŒ¹é…æŸå¤±å¼ é‡
            compatibility_penalty: å…¼å®¹æ€§æƒ©ç½šå¼ é‡
            step_count: å½“å‰è®­ç»ƒæ­¥æ•°ï¼Œç”¨äºæƒé‡è°ƒåº¦
            
        Returns:
            æ€»æŸå¤±å¼ é‡
        """
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯æ ‡é‡å¼ é‡
        latency = latency.squeeze() if latency.dim() > 0 else latency
        energy = energy.squeeze() if energy.dim() > 0 else energy
        area = area.squeeze() if area.dim() > 0 else area
        mismatch_loss = mismatch_loss.squeeze() if mismatch_loss.dim() > 0 else mismatch_loss
        compatibility_penalty = compatibility_penalty.squeeze() if compatibility_penalty.dim() > 0 else compatibility_penalty
        
        # è·å–å…¼å®¹æ€§æƒ©ç½šæƒé‡
        comp_penalty_weight = self.loss_weights.get('compatibility_penalty_weight', 100.0)
        comp_penalty = comp_penalty_weight * compatibility_penalty
        
        # è®¡ç®—é¢ç§¯é¢„ç®—æƒ©ç½šé¡¹
        area_budget_penalty = self._compute_area_budget_penalty(area, step_count)
        
        # æ ¹æ®æŸå¤±ç­–ç•¥è®¡ç®—æŸå¤±
        if self.loss_strategy == 'strategy_A':
            # Strategy A: å¤æ‚çš„å¯¹æ•°æŸå¤±è®¡ç®—
            edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_loss = self.loss_weights['area_weight'] * area
            mismatch_penalty = torch.log(1.0 + mismatch_loss * self.loss_weights['mismatch_penalty_weight'])
            loss = edp_loss + area_loss + mismatch_penalty + comp_penalty + area_budget_penalty
            
        elif self.loss_strategy == 'strategy_B':
            # Strategy B: åŠ æƒEDPæŸå¤±è®¡ç®—
            edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_loss = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights['mismatch_penalty_weight']
            loss = (self.loss_weights['edp_weight'] * edp_loss +
                   area_loss + mismatch_penalty + comp_penalty + area_budget_penalty)
            
        elif self.loss_strategy == 'log_edp_plus_area':
            # æ ‡å‡†ç­–ç•¥ï¼šlog(EDP) + é¢ç§¯æƒ©ç½š
            log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            loss = log_edp + area_penalty + mismatch_penalty + comp_penalty + area_budget_penalty
            
        elif self.loss_strategy == 'edp_plus_area':
            # EDP + é¢ç§¯æƒ©ç½š
            edp = latency * energy
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            loss = edp + area_penalty + mismatch_penalty + comp_penalty + area_budget_penalty

        elif self.loss_strategy == 'pure_edp':
            # Pure EDP optimisation without area or PE penalties
            edp = latency * energy
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            loss = edp + mismatch_penalty + comp_penalty + area_budget_penalty

        else:
            # é»˜è®¤ç­–ç•¥ï¼šä¸log_edp_plus_areaç›¸åŒ
            log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            loss = log_edp + area_penalty + mismatch_penalty + comp_penalty + area_budget_penalty
        
        # ç¡®ä¿è¿”å›æ ‡é‡å¼ é‡
        return loss.squeeze() if loss.dim() > 0 else loss

    def _apply_min_hw_bounds(self, min_hw: Dict[str, float], reset: bool = False):
        """Apply minimal hardware constraints.

        Args:
            min_hw: Dictionary returned by ``derive_minimal_hardware``.
            reset: If True, hardware parameters are reset exactly to the
                minimal values. If False, existing parameters are only clamped
                to be no smaller than the minima.
        """
        device = self.hw_params.log_num_pes.device

        min_num_pes = torch.tensor(float(min_hw.get('num_pes', 1)), device=device)
        current_pes = torch.exp(self.hw_params.log_num_pes.data)
        new_pes = min_num_pes if reset else torch.maximum(current_pes, min_num_pes)
        self.hw_params.log_num_pes.data = torch.log(new_pes)

        for level, param in self.hw_params.log_buffer_sizes_kb.items():
            if level not in min_hw:
                continue
            min_size = torch.tensor(float(min_hw[level]), device=param.device)
            current_size = torch.exp(param.data)
            new_size = min_size if reset else torch.maximum(current_size, min_size)
            param.data = torch.log(new_size)
    
    def _set_params_from_dict(self, params: Dict[str, Any]):
        """
        å°†æ‰å¹³åŒ–çš„å‚æ•°å­—å…¸è®¾ç½®åˆ°æ¨¡å‹å®ä¾‹ä¸­
        
        Args:
            params: åŒ…å«æ‰€æœ‰å‚æ•°çš„æ‰å¹³åŒ–å­—å…¸
        """
        # è®¾ç½®ç¡¬ä»¶å‚æ•°ï¼ˆPEæ•°é‡å›ºå®šä¸ºmin_hwæ¨å¯¼å€¼ï¼Œä¸å†ä»å‚æ•°è®¾ç½®ï¼‰
        for level in ['L0_Registers', 'L1_Accumulator', 'L2_Scratchpad']:
            key = f'{level.lower()}_size_kb'
            if key in params:
                device = self.hw_params.log_buffer_sizes_kb[level].device
                self.hw_params.log_buffer_sizes_kb[level].data = torch.log(torch.tensor(params[key], device=device))
        
        # è®¾ç½®æ˜ å°„å‚æ•° - åªä¸ºå®é™…å­˜åœ¨çš„on-chip bufferå±‚çº§è®¾ç½®å‚æ•°
        on_chip_levels = ['L0_Registers', 'L1_Accumulator', 'L2_Scratchpad']
        for dim_name in self.graph.problem_dims.keys():
            for level_name in on_chip_levels:
                # ç¡®ä¿level_nameåœ¨mapping.factorsä¸­å­˜åœ¨
                if level_name in self.mapping.factors:
                    temporal_key = f'{dim_name}_{level_name}_temporal'
                    spatial_key = f'{dim_name}_{level_name}_spatial'
                    
                    if temporal_key in params:
                        device = self.mapping.factors[level_name][dim_name]['temporal'].device
                        self.mapping.factors[level_name][dim_name]['temporal'].data = torch.log(torch.tensor(params[temporal_key], device=device))
                    if spatial_key in params:
                        device = self.mapping.factors[level_name][dim_name]['spatial'].device
                        self.mapping.factors[level_name][dim_name]['spatial'].data = torch.log(torch.tensor(params[spatial_key], device=device))
        
        # è®¾ç½®èåˆå‚æ•°
        if 'fusion_logits' in params:
            fusion_logits = params['fusion_logits']
            if isinstance(fusion_logits, list):
                fusion_logits = torch.tensor(fusion_logits, device=self.fusion_params.fusion_logits.device).unsqueeze(1)
            else:
                fusion_logits = fusion_logits.to(self.fusion_params.fusion_logits.device)
            self.fusion_params.fusion_logits.data = fusion_logits
    
    def _get_params_as_dict(self) -> Dict[str, Any]:
        """
        å°†å½“å‰æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºæ‰å¹³åŒ–å­—å…¸
        
        Returns:
            æ‰å¹³åŒ–çš„å‚æ•°å­—å…¸
        """
        params = {}
        
        # ç¡¬ä»¶å‚æ•°
        params['num_pes'] = self.hw_params.get_projected_num_pes().item()
        for level in ['L0_Registers', 'L1_Accumulator', 'L2_Scratchpad']:
            key = f'{level.lower()}_size_kb'
            params[key] = self.hw_params.get_buffer_size_kb(level).item()
        
        # æ˜ å°„å‚æ•°
        mapping_factors = self.mapping.get_all_factors()
        for dim_name, dim_factors in mapping_factors.items():
            for level_name, level_factors in dim_factors.items():
                params[f'{dim_name}_{level_name}_temporal'] = level_factors['temporal'].item()
                params[f'{dim_name}_{level_name}_spatial'] = level_factors['spatial'].item()
        
        # èåˆå‚æ•°
        fusion_logits = self.fusion_params.fusion_logits.squeeze()
        if fusion_logits.dim() == 0:  # æ ‡é‡æƒ…å†µ
            params['fusion_logits'] = [fusion_logits.item()]
        else:
            params['fusion_logits'] = fusion_logits.tolist()
        
        return params
    
    def _compute_loss_breakdown(self, latency, energy, area, mismatch_loss, compatibility_penalty, step_count=0):
        """
        è®¡ç®—lossçš„è¯¦ç»†ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬é¢ç§¯é¢„ç®—æƒ©ç½šé¡¹
        
        Args:
            latency: å»¶è¿Ÿå¼ é‡
            energy: èƒ½è€—å¼ é‡
            area: é¢ç§¯å¼ é‡
            mismatch_loss: ä¸åŒ¹é…æŸå¤±å¼ é‡
            compatibility_penalty: å…¼å®¹æ€§æƒ©ç½šå¼ é‡
            step_count: å½“å‰è®­ç»ƒæ­¥æ•°ï¼Œç”¨äºæƒé‡è°ƒåº¦
            
        Returns:
            åŒ…å«lossè¯¦ç»†ç»„æˆçš„å­—å…¸
        """
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯æ ‡é‡å¼ é‡
        latency = latency.squeeze() if latency.dim() > 0 else latency
        energy = energy.squeeze() if energy.dim() > 0 else energy
        area = area.squeeze() if area.dim() > 0 else area
        mismatch_loss = mismatch_loss.squeeze() if mismatch_loss.dim() > 0 else mismatch_loss
        compatibility_penalty = compatibility_penalty.squeeze() if compatibility_penalty.dim() > 0 else compatibility_penalty
        
        # è·å–å…¼å®¹æ€§æƒ©ç½šæƒé‡
        comp_penalty_weight = self.loss_weights.get('compatibility_penalty_weight', 100.0)
        comp_penalty = comp_penalty_weight * compatibility_penalty
        
        # è®¡ç®—é¢ç§¯é¢„ç®—æƒ©ç½šé¡¹
        area_budget_penalty = self._compute_area_budget_penalty(area, step_count)
        
        breakdown = {
            'strategy': self.loss_strategy,
            'latency': latency.item(),
            'energy': energy.item(),
            'area': area.item(),
            'area_budget_penalty': area_budget_penalty.item()
        }
        
        # æ ¹æ®æŸå¤±ç­–ç•¥è®¡ç®—å„ç»„æˆéƒ¨åˆ†
        if self.loss_strategy == 'strategy_A':
            edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_loss = self.loss_weights['area_weight'] * area
            mismatch_penalty = torch.log(1.0 + mismatch_loss * self.loss_weights['mismatch_penalty_weight'])
            breakdown.update({
                'log_edp': edp_loss.item(),
                'area_penalty': area_loss.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item()
            })
            
        elif self.loss_strategy == 'strategy_B':
            edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_loss = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights['mismatch_penalty_weight']
            weighted_edp = self.loss_weights['edp_weight'] * edp_loss
            breakdown.update({
                'weighted_log_edp': weighted_edp.item(),
                'area_penalty': area_loss.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item()
            })
            
        elif self.loss_strategy == 'log_edp_plus_area':
            log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            breakdown.update({
                'log_edp': log_edp.item(),
                'area_penalty': area_penalty.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item()
            })
            
        elif self.loss_strategy == 'edp_plus_area':
            edp = latency * energy
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            breakdown.update({
                'edp': edp.item(),
                'area_penalty': area_penalty.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item()
            })
            
        elif self.loss_strategy == 'pure_edp':
            edp = latency * energy
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            breakdown.update({
                'edp': edp.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item(),
                'area_not_in_loss': area.item()  # é¢ç§¯ä¸è®¡å…¥lossä½†æ˜¾ç¤º
            })
            
        else:
            # é»˜è®¤ç­–ç•¥ï¼šä¸log_edp_plus_areaç›¸åŒ
            log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
            area_penalty = self.loss_weights['area_weight'] * area
            mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
            breakdown.update({
                'log_edp': log_edp.item(),
                'area_penalty': area_penalty.item(),
                'mismatch_penalty': mismatch_penalty.item(),
                'compatibility_penalty': comp_penalty.item()
            })
        
        return breakdown
    
    def _compute_area_budget_penalty(self, area, step_count=0):
        """
        è®¡ç®—é¢ç§¯é¢„ç®—æƒ©ç½šé¡¹
        
        Args:
            area: å½“å‰é¢ç§¯ (mmÂ²)
            step_count: å½“å‰è®­ç»ƒæ­¥æ•°ï¼Œç”¨äºæƒé‡è°ƒåº¦
            
        Returns:
            é¢ç§¯é¢„ç®—æƒ©ç½šå€¼ (torch.Tensor)
        """
        from .config import Config
        config = Config.get_instance()
        
        # å¦‚æœæœªå¯ç”¨é¢ç§¯é¢„ç®—æˆ–é¢„ç®—ä¸ºNoneï¼Œè¿”å›0
        if not config.ENABLE_AREA_BUDGET or config.AREA_BUDGET_MM2 is None:
            return torch.tensor(0.0, device=area.device, dtype=area.dtype)
        
        budget = config.AREA_BUDGET_MM2
        tolerance = config.AREA_BUDGET_TOLERANCE
        strategy = config.AREA_BUDGET_PENALTY_STRATEGY
        
        # è®¡ç®—å½“å‰æƒé‡ï¼ˆæ”¯æŒæƒé‡è°ƒåº¦ï¼‰
        base_weight = config.AREA_BUDGET_PENALTY_WEIGHT
        if config.AREA_BUDGET_WEIGHT_SCHEDULE['enable']:
            schedule_config = config.AREA_BUDGET_WEIGHT_SCHEDULE
            initial_weight = schedule_config['initial_weight']
            final_weight = schedule_config['final_weight']
            warmup_steps = schedule_config['warmup_steps']
            schedule_type = schedule_config['schedule_type']
            
            if step_count < warmup_steps:
                if schedule_type == 'linear':
                    progress = step_count / warmup_steps
                    current_weight = initial_weight + (final_weight - initial_weight) * progress
                elif schedule_type == 'exponential':
                    progress = step_count / warmup_steps
                    current_weight = initial_weight * ((final_weight / initial_weight) ** progress)
                else:
                    current_weight = initial_weight
            else:
                current_weight = final_weight
        else:
            current_weight = base_weight
        
        # è®¡ç®—é¢„ç®—è¾¹ç•Œ
        lower_bound = budget * (1 - tolerance)
        upper_bound = budget * (1 + tolerance)
        
        # åœ¨å®¹å¿åŒºé—´å†…ä¸æ–½åŠ æƒ©ç½š
        if lower_bound <= area <= upper_bound:
            return torch.tensor(0.0, device=area.device, dtype=area.dtype)
        
        # è®¡ç®—åç¦»é‡
        if area < lower_bound:
            deviation = lower_bound - area
        else:  # area > upper_bound
            deviation = area - upper_bound
        
        # å½’ä¸€åŒ–åç¦»é‡ï¼ˆç›¸å¯¹äºé¢„ç®—çš„ç™¾åˆ†æ¯”ï¼‰
        normalized_deviation = deviation / budget
        
        # æ ¹æ®ç­–ç•¥è®¡ç®—æƒ©ç½š
        if strategy == 'quadratic':
            penalty = normalized_deviation ** 2
        elif strategy == 'linear':
            penalty = normalized_deviation
        elif strategy == 'huber':
            delta = config.AREA_BUDGET_HUBER_DELTA
            if normalized_deviation <= delta:
                penalty = 0.5 * (normalized_deviation ** 2)
            else:
                penalty = delta * (normalized_deviation - 0.5 * delta)
        elif strategy == 'exponential':
            penalty = torch.exp(normalized_deviation) - 1
        else:
            # é»˜è®¤ä½¿ç”¨äºŒæ¬¡æƒ©ç½š
            penalty = normalized_deviation ** 2
        
        # åº”ç”¨æƒé‡
        final_penalty = current_weight * penalty
        
        return final_penalty

    def update_best_result(
        self,
        loss: float,
        params: Dict[str, Any],
        metrics: Dict[str, float],
        trial: int,
        loss_breakdown: Dict[str, Any] = None,
    ):
        """æ›´æ–°æœç´¢è¿‡ç¨‹ä¸­çš„æœ€ä½³ç»“æœã€‚

        åŒæ—¶ç»´æŠ¤åŸºäº ``loss`` å’Œ ``metrics['edp']`` çš„ä¸¤å¥—æœ€ä¼˜è®°å½•ï¼š
        - ``best_loss`` ç›¸å…³å­—æ®µç”¨äºä¿æŒä¸åŸæœ‰è§¦å‘é€»è¾‘çš„å…¼å®¹æ€§ï¼›
        - ``best_edp`` ç›¸å…³å­—æ®µç”¨äºåœ¨ PhaseB ä¸­æ¢å¤ EDP æœ€ä¼˜é…ç½®ï¼Œå¹¶æœ€ç»ˆæ±‡æŠ¥ã€‚
        """

        improved_loss = loss < self.best_loss
        current_edp = metrics.get("edp", float("inf"))
        improved_edp = current_edp < self.best_edp

        if improved_loss:
            self.best_loss = loss
            self.best_params = params.copy()
            self.best_metrics = metrics.copy()

        if improved_edp:
            self.best_edp = current_edp
            self.best_edp_params = params.copy()
            self.best_edp_metrics = metrics.copy()
            self.best_discrete_factors = self._last_eval_discrete_factors
            if self.recorder is not None:
                self.recorder.update_best(metrics, key="edp")

        if (improved_loss or improved_edp) and self.logger:
            event_data = {"loss": loss, **metrics}
            if loss_breakdown:
                event_data["loss_breakdown"] = loss_breakdown
            self.logger.event("new_best", step=trial, metrics=event_data)
    
    from typing import Optional

    def log_trial(self, trial: int, loss: float, metrics: Dict[str, float], params: Dict[str, Any], is_best: Optional[bool] = None):
        """
        è®°å½•è¯•éªŒç»“æœ
        
        Args:
            trial: è¯•éªŒæ¬¡æ•°
            loss: æŸå¤±å€¼
            metrics: æ€§èƒ½æŒ‡æ ‡
            params: å‚æ•°å­—å…¸
            is_best: æ˜¯å¦ä¸ºæœ€ä½³ç»“æœ
        """
        if self.logger:
            num_pes_val = params.get('num_pes', self.hw_params.get_projected_num_pes().item())
            trial_data = {
                'searcher_type': self.__class__.__name__,
                'loss': loss,
                'metrics': {
                    'loss': loss,
                    'edp': metrics['edp'],
                    'latency_sec': metrics['latency_sec'],
                    'energy_pj': metrics['energy_pj'],
                    'area_mm2': metrics['area_mm2']
                },
                'hardware_params': {
                    'num_pes': num_pes_val,
                    'l0_size_kb': params.get('l0_registers_size_kb', 0),
                    'l1_size_kb': params.get('l1_accumulator_size_kb', 0),
                    'l2_size_kb': params.get('l2_scratchpad_size_kb', 0)
                },
                'fusion_decisions': self.fusion_params.get_fusion_decisions_serializable(self.graph),
                'best_so_far': is_best if is_best is not None else (loss <= self.best_loss)
            }

            self.logger.trial(trial, trial_data)
        
        # ------ Recorder é›†æˆ ------
        if self.recorder is not None:
            trial_row = {
                "trial": trial,
                "loss": loss,
                **metrics
            }
            self.recorder.record_trial(trial_row)


def get_random_valid_divisor(dim_size: int) -> int:
    """
    è·å–ç»™å®šç»´åº¦å¤§å°çš„éšæœºæœ‰æ•ˆçº¦æ•°
    
    Args:
        dim_size: ç»´åº¦å¤§å°
        
    Returns:
        éšæœºé€‰æ‹©çš„æœ‰æ•ˆçº¦æ•°
    """
    divisors = get_divisors(dim_size)
    return int(divisors[torch.randint(0, len(divisors), (1,)).item()].item())


class FADOSASearcher(BaseSearcher):
    """
    FA-DOSAæœç´¢å™¨ï¼šåŸºäºæ¢¯åº¦çš„äº¤æ›¿ä¼˜åŒ–
    """
    
    def __init__(self, graph, hw_params, mapping, fusion_params, perf_model, config, logger=None, recorder=None):
        super().__init__(graph, hw_params, mapping, fusion_params, perf_model, config, logger, recorder)
        
        # FA-DOSAç‰¹å®šå‚æ•°
        self.num_outer_steps = getattr(config, 'NUM_OUTER_STEPS', 5)
        self.num_mapping_steps = getattr(config, 'NUM_MAPPING_STEPS', 50)
        self.num_hardware_steps = getattr(config, 'NUM_HARDWARE_STEPS', 50)
        self.lr_mapping = getattr(config, 'LR_MAPPING', 0.01)
        self.lr_hardware = getattr(config, 'LR_HARDWARE', 0.01)
    
    def update_loss_weights(self, new_weights: dict):
        """Update loss weights dynamically for Pareto frontier scanning.
        
        Args:
            new_weights: Dictionary containing new weight values
        """
        self.loss_weights.update(new_weights)
        if self.logger:
            self.logger.console(f"Updated loss weights: {self.loss_weights}")

    def _snapshot_mapping(self):
        """Capture current mapping factors as plain floats for change tracking."""
        with torch.no_grad():
            factors = self.mapping.get_all_factors()
        snapshot = {}
        for dim, levels in factors.items():
            snapshot[dim] = {}
            for level, facs in levels.items():
                snapshot[dim][level] = {k: float(v.item()) for k, v in facs.items()}
        return snapshot
    
    def _snapshot_mapping_raw(self):
        """Capture raw mapping factors (exp of log-space) for baselineB diff."""
        snap = {}
        for lvl, dims in self.mapping.factors.items():
            snap[lvl] = {}
            for dim, dd in dims.items():
                t = float(torch.exp(dd["temporal"]).detach().cpu())
                s = float(torch.exp(dd["spatial"]).detach().cpu())
                # ä¸ºäº†å¯æ¯”æ€§ï¼Œå››èˆäº”å…¥æˆæ•´æ•°ï¼ˆæˆ–ä¿ç•™ä¸¤ä½å°æ•°ï¼‰
                snap.setdefault(dim, {})
                snap[dim].setdefault(lvl, {})
                snap[dim][lvl]["temporal"] = round(t)
                snap[dim][lvl]["spatial"] = round(s)
        return snap

    def _snapshot_fusion(self):
        """Capture current fusion decisions for change tracking."""
        decisions = self.fusion_params.get_fusion_decisions_serializable(self.graph)
        snapshot = {}
        for d in decisions:
            group = d["group"]
            key = "|".join(group) if isinstance(group, list) else str(group)
            snapshot[key] = d["fused"]
        return snapshot

    def _diff_mapping(self, prev, curr, tol: float = 1e-6, limit: int = 50):
        """Return a summary of mapping factor changes between two snapshots."""
        changes = []
        for dim, levels in curr.items():
            for level, facs in levels.items():
                for k, v in facs.items():
                    prev_v = prev.get(dim, {}).get(level, {}).get(k)
                    if prev_v is None or abs(v - prev_v) > tol:
                        if prev_v is None:
                            changes.append(f"{dim}.{level}.{k}: {v:.2f}")
                        else:
                            changes.append(f"{dim}.{level}.{k}: {prev_v:.2f}->{v:.2f}")
        if len(changes) > limit:
            return changes[:limit] + [f"... (+{len(changes) - limit} more)"]
        return changes

    def _diff_fusion(self, prev, curr, limit: int = 5):
        """Return a summary of fusion decision changes between two snapshots."""
        changes = []
        for group, fused in curr.items():
            prev_fused = prev.get(group)
            if prev_fused is None or fused != prev_fused:
                if prev_fused is None:
                    changes.append(f"{group}: {fused}")
                else:
                    changes.append(f"{group}: {prev_fused}->{fused}")
        if len(changes) > limit:
            return changes[:limit] + [f"... (+{len(changes) - limit} more)"]
        return changes
    
    def search(self, num_trials: int) -> Dict[str, Any]:
        """
        æ‰§è¡ŒFA-DOSAçš„äº¤æ›¿ä¼˜åŒ–æœç´¢
        
        Args:
            num_trials: è¿™é‡Œå¯¹åº”äºå¤–å±‚ä¼˜åŒ–æ­¥æ•°
            
        Returns:
            æœ€ä½³ç»“æœå­—å…¸
        """
        import os
        from .utils import save_configuration_to_json
        
        # ğŸ› ï¸ å¼€å¯å¼‚å¸¸æ£€æµ‹ï¼Œå®šä½å…·ä½“ç®—å­å †æ ˆ
        import torch
        torch.autograd.set_detect_anomaly(True)
        print("[DEBUG] Enabled autograd anomaly detection")
        
        # -------- è®¾å¤‡åŒæ­¥ --------
        device = self.config.DEVICE
        self.hw_params.to(device)
        self.mapping.to(device)
        self.fusion_params.to(device)

        if self.logger:
            self.logger.event("search_start", searcher_type="FA-DOSA", outer_steps=self.num_outer_steps)
            self.logger.console(f"Starting FA-DOSA search with {self.num_outer_steps} outer steps...")

        # ç¡®ä¿outputç›®å½•å­˜åœ¨
        os.makedirs('output', exist_ok=True)

        trial_count = 0

        # Snapshots for tracking mapping and fusion changes across outer steps
        prev_mapping_state = self._snapshot_mapping()
        prev_fusion_state = self._snapshot_fusion()

        # è®°å½•åŸºçº¿çº¦æŸä¸‹çš„ requires_grad çŠ¶æ€ï¼Œä»¥é˜²è¢«åç»­é˜¶æ®µè¦†ç›–
        hw_params_list = list(self.hw_params.parameters())
        mapping_params_list = list(self.mapping.parameters())
        fusion_params_list = list(self.fusion_params.parameters())
        init_hw_requires_grad = [p.requires_grad for p in hw_params_list]
        init_mapping_requires_grad = [p.requires_grad for p in mapping_params_list]
        init_fusion_requires_grad = [p.requires_grad for p in fusion_params_list]
        
        # äº¤æ›¿ä¼˜åŒ–å¾ªç¯
        for outer_step in range(self.num_outer_steps):
            if self.logger:
                self.logger.event("outer_step_start", index=outer_step + 1, total=self.num_outer_steps)
                
            
            # Phase A: ä¼˜åŒ–æ˜ å°„å’Œèåˆå‚æ•°ï¼ˆå†»ç»“ç¡¬ä»¶å‚æ•°ï¼‰
            if self.logger:
                self.logger.event("phase_start", phase="mapping_fusion")
                # Removed duplicate phase console

            # å†»ç»“ç¡¬ä»¶å‚æ•°
            for p in hw_params_list:
                p.requires_grad = False
            # æ¢å¤æ˜ å°„å’Œèåˆå‚æ•°åœ¨åŸºçº¿çº¦æŸä¸‹çš„ requires_grad çŠ¶æ€
            for p, flag in zip(mapping_params_list, init_mapping_requires_grad):
                p.requires_grad = flag
            for p, flag in zip(fusion_params_list, init_fusion_requires_grad):
                p.requires_grad = flag

            # æ”¶é›†å¯è®­ç»ƒçš„æ˜ å°„å’Œèåˆå‚æ•°
            map_opt_params = [p for p in mapping_params_list + fusion_params_list if p.requires_grad]
            if map_opt_params:
                print(f"\n[PHASE A] å¼€å§‹æ˜ å°„å’Œèåˆå‚æ•°ä¼˜åŒ– - å­¦ä¹ ç‡: {self.lr_mapping}")
                print(f"[PHASE A] å¯è®­ç»ƒå‚æ•°æ•°é‡: {len(map_opt_params)}")
                optimizer_map = optim.Adam(map_opt_params, lr=self.lr_mapping)
                
                # ğŸ› ï¸ 1. ç¡®è®¤å‚æ•°çœŸçš„åœ¨ä¼˜åŒ–åˆ—è¡¨é‡Œ
                for name, p in zip(["map_param_%d" % i for i in range(len(map_opt_params))], map_opt_params):
                    # å®‰å…¨å¤„ç†æ ‡é‡å’Œå‘é‡å‚æ•°
                    if p.data.numel() == 1:  # æ ‡é‡å‚æ•°
                        value_str = f"{p.data.item():.6f}"
                    else:  # å‘é‡å‚æ•°
                        value_str = str(p.data.flatten()[:5].tolist())
                    print(f"[DEBUG] param {name}: requires_grad={p.requires_grad}, shape={p.shape}, value={value_str}")

                for i in range(self.num_mapping_steps):
                    optimizer_map.zero_grad()
                    
                    # ğŸ› ï¸ æ¢¯åº¦è¿é€šæ€§éªŒè¯æ¢é’ˆï¼ˆä»…åœ¨ç¬¬ä¸€æ­¥æ‰§è¡Œï¼‰
                    if i == 0 and getattr(self.config, "DEBUG_GRAD_PROJ", True):
                        # 1) ä»»é€‰ä¸€ä¸ªå¯è®­ç»ƒçš„æ˜ å°„å¶å­å‚æ•° p
                        p = next((q for q in self.mapping.parameters() if q.requires_grad), None)
                        if p is None:
                            print("[PROBE] no trainable mapping param.")
                        else:
                            # 2) æŠŠ"æŠ•å½±åçš„æŸä¸ªå¼ é‡"å–å‡ºæ¥ï¼ˆä»»é€‰ä¸€ä¸ªä»£è¡¨æ€§åˆ†é‡ï¼‰
                            proj = self.mapping.get_all_factors()  # ä½¿ç”¨å®é™…çš„æŠ•å½±å‡½æ•°å
                            # proj åº”è¯¥æ˜¯ä¸ª dict ç»“æ„ï¼Œé‡Œé¢æ˜¯ tensorï¼›æŒ‘ä¸€ä¸ª requires_grad=True çš„
                            t = None
                            for _, levels in proj.items():
                                for _, dims in levels.items():
                                    for name, v in dims.items():
                                        if isinstance(v, torch.Tensor) and v.requires_grad:
                                            t = v
                                            break
                                    if t is not None: break
                                if t is not None: break
                            
                            if t is None:
                                print("[PROBE] projected tensor has no requires_grad=True (graph likely cut).")
                            else:
                                # 3) ä¿ç•™éå¶å­æ¢¯åº¦ï¼Œåšä¸€ä¸ªæå°çš„ dummy loss ç›´æ¥ä»æŠ•å½±é‡åä¼ 
                                t.retain_grad()
                                self.mapping.zero_grad(set_to_none=True)
                                dummy_loss = t.sum()
                                dummy_loss.backward(retain_graph=True)
                                
                                print(f"[PROBE] p.grad is None? {p.grad is None}")
                                if p.grad is not None:
                                    print(f"[PROBE] p.grad mean abs = {p.grad.abs().mean().item():.3e}")
                                print(f"[PROBE] t.grad is None? {t.grad is None}")
                                if t.grad is not None:
                                    print(f"[PROBE] t.grad mean abs = {t.grad.abs().mean().item():.3e}")
                                
                                # æ¸…æ¢¯åº¦å›åˆ°æ­£å¸¸è·¯å¾„
                                self.mapping.zero_grad(set_to_none=True)

                    # ç›´æ¥è®¡ç®—æŸå¤±ï¼ˆä¿æŒæ¢¯åº¦å›¾ï¼‰
                    latency, energy, area, mismatch_loss, compatibility_penalty = self.perf_model(
                        self.graph, self.hw_params, self.mapping, self.fusion_params
                    )

                    if self.logger is not None:
                        self.logger.event(
                            "fusion_decisions",
                            decisions=self.fusion_params.get_fusion_decisions_serializable(self.graph),
                        )

                    # ä½¿ç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—æ–¹æ³•
                    loss = self._compute_loss(latency, energy, area, mismatch_loss, compatibility_penalty, step_count=trial_count)

                    # ğŸ› ï¸ 2. æ‰“å° loss.backward() ä¹‹å‰çš„è®¡ç®—å›¾ä¿¡æ¯
                    print(f"[DEBUG] loss grad_fn={loss.grad_fn}")
                    
                    # ğŸ› ï¸ 3. æ£€æŸ¥å‚æ•°çš„ .grad_fn
                    test_param = map_opt_params[0]
                    print(f"[DEBUG] param grad_fn={test_param.grad_fn}, requires_grad={test_param.requires_grad}")

                    # åå‘ä¼ æ’­
                    loss.backward()
                    
                    # ğŸ› ï¸ 4. loss.backward() ä¹‹åçœ‹æ¢¯åº¦
                    for i, p in enumerate(map_opt_params[:3]):
                        print(f"[DEBUG] param{i} grad={p.grad}")
                    
                    # ğŸ› ï¸ éªŒè¯æŠ•å½±å¼ é‡çš„æ¢¯åº¦è¿é€šæ€§
                    if i == 0:  # ä»…åœ¨ç¬¬ä¸€æ­¥æ£€æŸ¥
                        proj_factors = self.mapping.get_all_factors()
                        proj_grad_count = 0
                        proj_none_count = 0
                        for dim_name, levels in proj_factors.items():
                            for level_name, dims in levels.items():
                                for factor_type, tensor in dims.items():
                                    if isinstance(tensor, torch.Tensor) and tensor.requires_grad:
                                        if tensor.grad is None:
                                            proj_none_count += 1
                                        else:
                                            proj_grad_count += 1
                        print(f"[PROBE] Projected tensors: {proj_grad_count} with grad, {proj_none_count} with None grad")

                    # è®¡ç®—æ¢¯åº¦èŒƒæ•°å¹¶æ‰“å°æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦
                    total_grad_norm = 0.0
                    grad_norms = {}

                    for name, param in [
                        ('mapping', list(self.mapping.parameters())), 
                        ('fusion', [self.fusion_params.fusion_logits])
                    ]:
                        param_grad_norm = 0.0
                        param_count = 0
                        
                        for idx, p in enumerate(param if name == 'mapping' else param):
                            if p.grad is not None:
                                # å•ä¸ªå‚æ•°çš„æ¢¯åº¦ L2 èŒƒæ•°
                                param_norm = p.grad.data.norm(2)
                                print(f"[DEBUG] {name} param{idx} grad_norm={param_norm.item():.6e}")
                                # ä¹Ÿå¯ä»¥æ‰“å°å®Œæ•´çš„æ¢¯åº¦å‘é‡ï¼ˆè°¨æ…ï¼Œå¯èƒ½å¾ˆé•¿ï¼‰
                                # print(f"[DEBUG] {name} param{idx} grad={p.grad.data.view(-1)[:10]} ...")
                                
                                param_grad_norm += param_norm.item() ** 2
                                param_count += 1
                            else:
                                print(f"[DEBUG] {name} param{idx} grad=None")

                        if param_count > 0:
                            param_grad_norm = (param_grad_norm ** 0.5)
                            grad_norms[name] = param_grad_norm
                            total_grad_norm += param_grad_norm ** 2

                    total_grad_norm = total_grad_norm ** 0.5

                    print(f"[DEBUG] æ¢¯åº¦èŒƒæ•°: æ€»è®¡={total_grad_norm:.6f}, "
                        f"æ˜ å°„={grad_norms.get('mapping', 0.0):.6f}, "
                        f"èåˆ={grad_norms.get('fusion', 0.0):.6f}")


                    # è®¡ç®—å‚æ•°åˆ†å¸ƒç»Ÿè®¡
                    param_stats = {}
                    # æ˜ å°„å‚æ•°ç»Ÿè®¡
                    mapping_values = []
                    for p in self.mapping.parameters():
                        if p.requires_grad:
                            mapping_values.extend(p.data.flatten().tolist())
                    if mapping_values:
                        param_stats['mapping'] = {
                            'min': min(mapping_values),
                            'max': max(mapping_values),
                            'mean': sum(mapping_values) / len(mapping_values)
                        }
                    
                    # èåˆå‚æ•°ç»Ÿè®¡
                    if self.fusion_params.fusion_logits.requires_grad:
                        fusion_values = self.fusion_params.fusion_logits.data.flatten().tolist()
                        param_stats['fusion'] = {
                            'min': min(fusion_values),
                            'max': max(fusion_values),
                            'mean': sum(fusion_values) / len(fusion_values)
                        }
                    
                    # æ‰“å°å‚æ•°ç»Ÿè®¡
                    for param_type, stats in param_stats.items():
                        print(f"[DEBUG] {param_type}å‚æ•°åˆ†å¸ƒ: min={stats['min']:.6f}, max={stats['max']:.6f}, mean={stats['mean']:.6f}")

                    # è®°å½•å†å²æ•°æ®ç”¨äºå¯è§†åŒ–
                    current_step = len(self.loss_history)
                    self.loss_history.append(loss.item())
                    self.grad_norm_history.append(total_grad_norm)
                    self.step_history.append(current_step)
                    self.phase_history.append('A')
                    # è®°å½•å½“å‰å‚æ•°çŠ¶æ€ç”¨äºçƒ­åŠ›å›¾
                    current_param_snapshot = {}
                    if 'mapping' in param_stats:
                        current_param_snapshot['mapping'] = param_stats['mapping']
                    if 'fusion' in param_stats:
                        current_param_snapshot['fusion'] = param_stats['fusion']
                    self.param_history.append(current_param_snapshot)

                    # ---- è°ƒè¯•æ—¥å¿—è®°å½•ï¼ˆPhase Aï¼‰ ----
                    if self.recorder is not None:
                        try:
                            first_map_grad = next((p.grad for p in self.mapping.parameters() if p.grad is not None), None)
                            mapping_grad_mean = float(first_map_grad.abs().mean().item()) if first_map_grad is not None else 0.0
                        except StopIteration:
                            mapping_grad_mean = 0.0
                        fusion_grad = self.fusion_params.fusion_logits.grad
                        fusion_grad_mean = float(fusion_grad.abs().mean().item()) if fusion_grad is not None else 0.0
                        debug_snapshot = {
                            "trial": trial_count + 1,
                            "phase": "A_Mapping_Fusion",
                            "outer_step": outer_step,
                            "inner_step": i,
                            "loss": loss.item(),
                            "loss_breakdown": {
                                "log_edp": (torch.log(latency + 1e-9) + torch.log(energy + 1e-9)).item(),
                                "area_penalty": (self.loss_weights['area_weight'] * area).item(),
                                "mismatch_penalty": mismatch_loss.item(),
                                "compatibility_penalty": compatibility_penalty.item()
                            },
                            "learning_rate": self.lr_mapping,
                            "gradients": {
                                "mapping_sample_grad_mean_abs": mapping_grad_mean,
                                "fusion_logits_grad_mean_abs": fusion_grad_mean
                            }
                        }
                        self.recorder.log_coopt_debug_step(debug_snapshot)

                    optimizer_map.step()

                    # é‡æ–°è®¡ç®—æ˜ å°„æ›´æ–°åçš„æ€§èƒ½æŒ‡æ ‡å’ŒæŸå¤±
                    with torch.no_grad():
                        latency, energy, area, mismatch_loss, compatibility_penalty = self.perf_model(
                            self.graph, self.hw_params, self.mapping, self.fusion_params
                        )
                        loss = self._compute_loss(latency, energy, area, mismatch_loss, compatibility_penalty,
                                                   step_count=trial_count)
                        metrics_current = {
                            'latency_sec': latency.item(),
                            'energy_pj': energy.item(),
                            'area_mm2': area.item(),
                            'edp': (latency * energy).item(),
                            'log_edp': (torch.log(latency + 1e-9) + torch.log(energy + 1e-9)).item(),
                            'mismatch_loss': mismatch_loss.item()
                        }
                        loss_breakdown = self._compute_loss_breakdown(
                            latency, energy, area, mismatch_loss, compatibility_penalty, step_count=trial_count
                        )
                        current_params = self._get_params_as_dict()
                
                    # æ·»åŠ ç¼ºå¤±çš„æ—¥å¿—è®°å½•å’Œlossè¯¦ç»†ç»„æˆæ‰“å° - æ¯æ­¥éƒ½æ‰“å°
                    print(f"\n[DEBUG] Phase A - Outer Step {outer_step+1}, Inner Step {i+1}:")
                    
                    # è®¡ç®—å¹¶æ˜¾ç¤ºlossçš„è¯¦ç»†ç»„æˆéƒ¨åˆ†
                    comp_penalty_weight = self.loss_weights.get('compatibility_penalty_weight', 100.0)
                    comp_penalty = comp_penalty_weight * compatibility_penalty
                    
                    if self.loss_strategy == 'strategy_A':
                        edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                        area_loss = self.loss_weights['area_weight'] * area
                        mismatch_penalty = torch.log(1.0 + mismatch_loss * self.loss_weights['mismatch_penalty_weight'])
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (strategy_A): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - Log(EDP): {edp_loss.item():.6f}")
                        print(f"[DEBUG]   - Areaæƒ©ç½š: {area_loss.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        
                    elif self.loss_strategy == 'strategy_B':
                        edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                        area_loss = self.loss_weights['area_weight'] * area
                        mismatch_penalty = mismatch_loss * self.loss_weights['mismatch_penalty_weight']
                        weighted_edp = self.loss_weights['edp_weight'] * edp_loss
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (strategy_B): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - åŠ æƒLog(EDP): {weighted_edp.item():.6f}")
                        print(f"[DEBUG]   - Areaæƒ©ç½š: {area_loss.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        
                    elif self.loss_strategy == 'log_edp_plus_area':
                        log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                        area_penalty = self.loss_weights['area_weight'] * area
                        mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (log_edp_plus_area): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - Log(EDP): {log_edp.item():.6f}")
                        print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        
                    elif self.loss_strategy == 'edp_plus_area':
                        edp = latency * energy
                        area_penalty = self.loss_weights['area_weight'] * area
                        mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (edp_plus_area): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - EDP: {edp.item():.6f}")
                        print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        
                    elif self.loss_strategy == 'pure_edp':
                        edp = latency * energy
                        mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                        area_budget_penalty = self._compute_area_budget_penalty(area, i)
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (pure_edp): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - EDP: {edp.item():.6f}")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        print(f"[DEBUG]   - é¢ç§¯é¢„ç®—æƒ©ç½š: {area_budget_penalty.item():.6f}")
                        print(f"[DEBUG]   - é¢ç§¯: {area.item():.2f} mmÂ² (åŒ…å«åŸºç¡€é¢ç§¯ï¼Œé¢„ç®—æƒ©ç½šå·²å•ç‹¬è®¡ç®—)")
                        
                    else:
                        # é»˜è®¤ç­–ç•¥
                        log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                        area_penalty = self.loss_weights['area_weight'] * area
                        mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                        print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (é»˜è®¤ç­–ç•¥): æ€»è®¡={loss.item():.6f}")
                        print(f"[DEBUG]   - Log(EDP): {log_edp.item():.6f}")
                        print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                        print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                        print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                        
                    # æ˜¾ç¤ºåŸºç¡€æ€§èƒ½æŒ‡æ ‡
                    print(f"[DEBUG] åŸºç¡€æŒ‡æ ‡: å»¶è¿Ÿ={latency.item():.2e}s, èƒ½è€—={energy.item():.2e}pJ")
                    
                    # æ¯æ­¥éƒ½æ›´æ–°trial_countå’Œè®°å½•æ—¥å¿—
                    trial_count += 1
                    if i % 10 == 0:  # ä¿æŒåŸæœ‰çš„æ¯10æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—çš„é€»è¾‘
                        self.log_trial(trial_count, loss.item(), metrics_current, current_params)

                    # é€€ç«æ¸©åº¦
                    # self.mapping.anneal_tau()
                    # print(f"[PHASE A] tau = {self.mapping.tau:.6f}")

                    # æ›´æ–°æœ€ä½³ç»“æœ
                    trial_count += 1
                    old_best_loss = self.best_loss
                    self.update_best_result(loss.item(), current_params, metrics_current, trial_count, loss_breakdown)

                    # è´¨é‡é©±åŠ¨çš„è§¦å‘ï¼šå½“æ‰¾åˆ°æ–°çš„å…¨å±€æœ€ä¼˜è§£æ—¶ä¿å­˜é…ç½®
                    if loss.item() < old_best_loss:
                        self._save_validation_config(trial_count, "quality_driven")

                    # å¤šæ ·æ€§é©±åŠ¨çš„è§¦å‘ï¼šå‘¨æœŸæ€§ä¿å­˜é…ç½®
                    if i % 50 == 0:
                        self._save_validation_config(trial_count, "diversity_driven")

                    # è®°å½•æ—¥å¿—
                    if i % 10 == 0:
                        self.log_trial(trial_count, loss.item(), metrics_current, current_params)

            # Restore EDP-optimal parameters from Phase A before hardware optimization
            _skip_restore = getattr(self, "skip_restore_best_mapping", False)
            if (self.best_edp_params is not None) and (not _skip_restore):
                self._set_params_from_dict(self.best_edp_params)
                if self.logger:
                    self.logger.console("Restored best EDP parameters from Phase A before hardware optimization.")
            else:
                if self.logger:
                    if _skip_restore:
                        self.logger.console("Skip restoring best mapping (baselineB).")
                    else:
                        self.logger.console("No EDP-optimal parameters found in Phase A, continuing with current parameters.")

            # Enable Phase-B frozen mapping if we have a snapshot
            _skip_restore = getattr(self, "skip_restore_best_mapping", False)
            if _skip_restore:
                self._freeze_discrete = False
                self.best_discrete_factors = None  # ä¿é™©ï¼šåˆ«å†ç”¨ A æœŸçš„ç¦»æ•£å¿«ç…§
            else:
                self._freeze_discrete = self.best_discrete_factors is not None
            try:
                self.mapping.eval()
            except Exception:
                pass
            try:
                self.fusion_params.eval()
            except Exception:
                pass


            # æ ¹æ®å½“å‰æ˜ å°„æ¨å¯¼æœ€å°ç¡¬ä»¶è§„æ¨¡ï¼Œä½œä¸ºç¡¬ä»¶ä¼˜åŒ–çš„èµ·ç‚¹
            with torch.no_grad():
                # æ¢å¤Phase Aä¸­çš„æœ€ä½³æ˜ å°„/èåˆé…ç½®ï¼Œç¡®ä¿åç»­ç¡¬ä»¶æœç´¢åŸºäºæœ€ä¼˜æ˜ å°„
                _skip_restore = getattr(self, "skip_restore_best_mapping", False)
                if (self.best_edp_params is not None) and (not _skip_restore):
                    print("[DEBUG] Phase Aç»“æŸ - æ¢å¤æœ€ä½³æ˜ å°„/èåˆé…ç½® (EDP æœ€ä¼˜)")
                    self._set_params_from_dict(self.best_edp_params)
                else:
                    if _skip_restore:
                        print("[DEBUG] Phase Aç»“æŸ - è·³è¿‡æ¢å¤æœ€ä½³æ˜ å°„ï¼ˆbaselineBï¼‰")
                    else:
                        print("[DEBUG] Phase Aç»“æŸ - æ— å¯æ¢å¤çš„æœ€ä½³ EDP é…ç½®ï¼Œä½¿ç”¨å½“å‰å‚æ•°")

                # è®°å½•å½“å‰ç¡¬ä»¶å‚æ•°ï¼ˆPhase Aç»“æŸæ—¶ï¼‰
                current_hw_before = {
                    'num_pes': self.hw_params.get_projected_num_pes().item(),
                    'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                    'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                    'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                }

                min_hw = derive_minimal_hardware(self.mapping, self.config)
                print(f"\n[DEBUG] Phase Aç»“æŸ - æ¨å¯¼çš„æœ€å°ç¡¬ä»¶éœ€æ±‚: {min_hw}")
                print(f"[DEBUG] Phase Aç»“æŸ - å½“å‰ç¡¬ä»¶é…ç½®: {current_hw_before}")
                
                # Apply minimal hardware bounds only if configured to do so
                if self.config.APPLY_MIN_HW_BOUNDS:
                    print(f"[DEBUG] åº”ç”¨æœ€å°ç¡¬ä»¶çº¦æŸ (reset={self.config.RESET_TO_MIN_HW})")
                    # Reset hardware to the minimal configuration if configured to do so.
                    # The number of PEs is deterministically determined by ``min_hw`` when reset=True.
                    self._apply_min_hw_bounds(min_hw, reset=self.config.RESET_TO_MIN_HW)
                    
                    # è®°å½•åº”ç”¨çº¦æŸåçš„ç¡¬ä»¶å‚æ•°
                    current_hw_after = {
                        'num_pes': self.hw_params.get_projected_num_pes().item(),
                        'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                        'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                        'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                    }
                    print(f"[DEBUG] åº”ç”¨çº¦æŸåç¡¬ä»¶é…ç½®: {current_hw_after}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å‚æ•°å‘ç”Ÿå˜åŒ–
                    changed_params = []
                    for key in current_hw_before:
                        if abs(current_hw_before[key] - current_hw_after[key]) > 1e-6:
                            changed_params.append(f"{key}: {current_hw_before[key]:.2f} -> {current_hw_after[key]:.2f}")
                    
                    if changed_params:
                        print(f"[DEBUG] âš ï¸  ç¡¬ä»¶å‚æ•°å‘ç”Ÿå˜åŒ–: {', '.join(changed_params)}")
                    else:
                        print(f"[DEBUG] âœ“ ç¡¬ä»¶å‚æ•°æœªå‘ç”Ÿå˜åŒ–")
                else:
                    print(f"[DEBUG] è·³è¿‡æœ€å°ç¡¬ä»¶çº¦æŸåº”ç”¨ (APPLY_MIN_HW_BOUNDS=False)")
                    current_hw_after = {
                        'num_pes': self.hw_params.get_projected_num_pes().item(),
                        'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                        'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                        'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                    }
                    assert all(abs(current_hw_before[k] - current_hw_after[k]) < 1e-6 for k in current_hw_before), (
                        "Hardware parameters changed despite APPLY_MIN_HW_BOUNDS=False"
                    )
                    print("[DEBUG] âœ“ ç¡¬ä»¶å‚æ•°æœªå‘ç”Ÿå˜åŒ– (APPLY_MIN_HW_BOUNDS=False)")

            # AæœŸç»“æŸ â†’ BæœŸå¼€å§‹ è¿™ä¸€å¤§æ®µé‡Œï¼Œé è¿‘ä½ æ‰“å° before/after snapshot çš„é™„è¿‘ï¼ŒåŠ ï¼š
            _print_requires_grad_flags(self, tag="[FLAGS][A->B]")
            print(f"[FLAGS][A->B] runner_name={getattr(self,'runner_name','?')}, "
                  f"skip_restore_best_mapping={getattr(self,'skip_restore_best_mapping',False)}, "
                  f"_freeze_discrete={getattr(self,'_freeze_discrete',None)}, "
                  f"has_best_discrete={self.best_discrete_factors is not None}")
            
            print("[DEBUG] BEFORE snapshot (projected) below is what diff SHOULD use as baseline:")
            before_proj = _dump_mapping_projected(self.mapping, tag="[PROJ][before_diff]")
            
            print("[DEBUG] AFTER  snapshot (projected):")
            after_proj  = _dump_mapping_projected(self.mapping, tag="[PROJ][after_phaseA]")
            
            # === å…³é”®ï¼šæŠŠ diff çš„åŸºçº¿æ”¹æˆ before_projï¼Œé¿å…ç”¨åˆ°"æ›´æ—©çš„ init å£å¾„" ===
            try:
                self_prev = getattr(self, "_prev_mapping_state_for_debug", None)
                if self_prev is None:
                    setattr(self, "_prev_mapping_state_for_debug", before_proj)
                    print("[DEBUG] prev_mapping_state_for_debug was None -> set to before_proj")
                else:
                    # ç»™å‡ºå“ˆå¸Œï¼Œæ–¹ä¾¿æ ¸å¯¹åˆ°åº•æ¯”è¾ƒçš„æ˜¯è°
                    print("[DEBUG] prev_mapping_state_for_debug already set (not changing).")
            except Exception as e:
                print(f"[DEBUG] prev_mapping_state_for_debug set failed: {e}")
            
            # Report mapping and fusion parameter changes - ä½¿ç”¨ä¸åŒå£å¾„
            if getattr(self, "runner_name", "") == "baselineB":
                # baselineB ä½¿ç”¨ raw å£å¾„ï¼Œé¿å…æŠ•å½±ç­–ç•¥çš„"å£å¾„å·®"
                print("[DEBUG] baselineB: using RAW diff mode")
                prev_raw = getattr(self, "_prev_mapping_state_raw", None) or self._snapshot_mapping_raw()
                curr_raw = self._snapshot_mapping_raw()
                mapping_changes = self._diff_mapping(prev_raw, curr_raw)
                setattr(self, "_prev_mapping_state_raw", curr_raw)
                print("[DEBUG] diff baseline=raw (exp of log-space), baselineB mode.")
                # ä¸ºäº†åç»­ä»£ç å…¼å®¹æ€§ï¼Œä¹Ÿå®šä¹‰ current_mapping_state
                current_mapping_state = self._snapshot_mapping()
            else:
                # å…¶å®ƒ baseline ä»ç”¨ projected å£å¾„
                print("[DEBUG] before diff snapshot (projected):")
                print(self._snapshot_mapping())
                current_mapping_state = self._snapshot_mapping()  # = after_proj
                
                # å¼ºåˆ¶ä»¥"åˆšåˆšå–åˆ°çš„ before_proj"ä½œä¸ºåŸºçº¿
                prev_for_diff = before_proj
                mapping_changes = self._diff_mapping(prev_for_diff, current_mapping_state)
                print("[DEBUG] diff baseline=before_proj (projected), not runner_init/other snapshots.")
                
                # æ›´æ–°ä¸‹ä¸€è½®çš„åŸºçº¿
                setattr(self, "_prev_mapping_state_for_debug", current_mapping_state)
            
            print("[DEBUG] after Phase A snapshot (projected):")
            print(self._snapshot_mapping()) 
            if mapping_changes:
                print(f"[DEBUG] âš ï¸ æ˜ å°„å‚æ•°å˜åŒ–: {', '.join(mapping_changes)}")
            else:
                print(f"[DEBUG] âœ“ æ˜ å°„å‚æ•°æœªå˜åŒ–")
            prev_mapping_state = current_mapping_state

            current_fusion_state = self._snapshot_fusion()
            fusion_changes = self._diff_fusion(prev_fusion_state, current_fusion_state)
            if fusion_changes:
                print(f"[DEBUG] âš ï¸ èåˆå†³ç­–å˜åŒ–: {', '.join(fusion_changes)}")
            else:
                print(f"[DEBUG] âœ“ èåˆå†³ç­–æœªå˜åŒ–")
            prev_fusion_state = current_fusion_state

            # Phase B: ä¼˜åŒ–ç¡¬ä»¶å‚æ•°ï¼ˆå†»ç»“æ˜ å°„å’Œèåˆå‚æ•°ï¼‰
            if self.logger:
                self.logger.event("phase_start", phase="hardware")
                # Removed duplicate phase console

            # å†»ç»“æ˜ å°„å’Œèåˆå‚æ•°
            for p in mapping_params_list + fusion_params_list:
                p.requires_grad = False
            # æ¢å¤ç¡¬ä»¶å‚æ•°åœ¨åŸºçº¿çº¦æŸä¸‹çš„ requires_grad çŠ¶æ€
            for p, flag in zip(hw_params_list, init_hw_requires_grad):
                p.requires_grad = flag

            # æ”¶é›†å¯è®­ç»ƒçš„ç¡¬ä»¶å‚æ•°
            hw_opt_params = [p for p in hw_params_list if p.requires_grad]
            if hw_opt_params:
                print(f"\n[PHASE B] å¼€å§‹ç¡¬ä»¶å‚æ•°ä¼˜åŒ– - å­¦ä¹ ç‡: {self.lr_hardware}")
                print(f"[PHASE B] å¯è®­ç»ƒå‚æ•°æ•°é‡: {len(hw_opt_params)}")
                optimizer_hw = optim.Adam(hw_opt_params, lr=self.lr_hardware)
                
                # æ‰“å°Phase Bå¼€å§‹å‰çš„åˆå§‹ç¡¬ä»¶é…ç½®
                with torch.no_grad():
                    initial_hw_config = {
                        'num_pes': self.hw_params.get_projected_num_pes().item(),
                        'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                        'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                        'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                    }
                    # è®¡ç®—åˆå§‹é¢ç§¯
                    _, _, initial_area, _, _ = self.perf_model(
                        self.graph, self.hw_params, self.mapping, self.fusion_params
                    )
                    print(f"\n[HARDWARE] Phase B å¼€å§‹ - åˆå§‹ç¡¬ä»¶é…ç½®:")
                    print(f"[HARDWARE]   PEæ•°é‡: {initial_hw_config['num_pes']:.0f}")
                    print(f"[HARDWARE]   L0ç¼“å­˜: {initial_hw_config['L0_size_kb']:.2f} KB")
                    print(f"[HARDWARE]   L1ç¼“å­˜: {initial_hw_config['L1_size_kb']:.2f} KB")
                    print(f"[HARDWARE]   L2ç¼“å­˜: {initial_hw_config['L2_size_kb']:.2f} KB")
                    print(f"[HARDWARE]   æ€»é¢ç§¯: {initial_area.item():.2f} mmÂ²")
                    print(f"[HARDWARE] å¼€å§‹ {self.num_hardware_steps} æ­¥ç¡¬ä»¶ä¼˜åŒ–...\n")

                for i in range(self.num_hardware_steps):
                    optimizer_hw.zero_grad()

                    # ç›´æ¥è®¡ç®—æŸå¤±ï¼ˆä¿æŒæ¢¯åº¦å›¾ï¼‰
                    latency, energy, area, mismatch_loss, compatibility_penalty = self.perf_model(
                        self.graph, self.hw_params, self.mapping, self.fusion_params
                    )

                    if self.logger is not None:
                        self.logger.event(
                            "fusion_decisions",
                            decisions=self.fusion_params.get_fusion_decisions_serializable(self.graph),
                        )

                    # ä½¿ç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—æ–¹æ³•
                    loss = self._compute_loss(latency, energy, area, mismatch_loss, compatibility_penalty, step_count=trial_count)

                    # åå‘ä¼ æ’­
                    loss.backward()

                    # è®¡ç®—ç¡¬ä»¶å‚æ•°æ¢¯åº¦èŒƒæ•°
                    hw_grad_norm = 0.0
                    hw_grad_details = {}
                    for name, param in [('log_num_pes', self.hw_params.log_num_pes), 
                                       ('log_l0_kb', self.hw_params.log_buffer_sizes_kb['L0_Registers']),
                                       ('log_l1_kb', self.hw_params.log_buffer_sizes_kb['L1_Accumulator']),
                                       ('log_l2_kb', self.hw_params.log_buffer_sizes_kb['L2_Scratchpad'])]:
                        if param.grad is not None:
                            param_norm = param.grad.data.norm(2).item()
                            hw_grad_details[name] = param_norm
                            hw_grad_norm += param_norm ** 2
                    hw_grad_norm = hw_grad_norm ** 0.5
                    
                    print(f"[DEBUG] ç¡¬ä»¶æ¢¯åº¦èŒƒæ•°: æ€»è®¡={hw_grad_norm:.6f}, PE={hw_grad_details.get('log_num_pes', 0.0):.6f}, L0={hw_grad_details.get('log_l0_kb', 0.0):.6f}, L1={hw_grad_details.get('log_l1_kb', 0.0):.6f}, L2={hw_grad_details.get('log_l2_kb', 0.0):.6f}")

                    # è®¡ç®—ç¡¬ä»¶å‚æ•°åˆ†å¸ƒç»Ÿè®¡
                    hw_param_values = []
                    hw_param_details = {}
                    for name, param in [('log_num_pes', self.hw_params.log_num_pes), 
                                       ('log_l0_kb', self.hw_params.log_buffer_sizes_kb['L0_Registers']),
                                       ('log_l1_kb', self.hw_params.log_buffer_sizes_kb['L1_Accumulator']),
                                       ('log_l2_kb', self.hw_params.log_buffer_sizes_kb['L2_Scratchpad'])]:
                        if param.requires_grad:
                            param_val = param.data.item()
                            hw_param_values.append(param_val)
                            hw_param_details[name] = param_val
                    
                    if hw_param_values:
                        hw_stats = {
                            'min': min(hw_param_values),
                            'max': max(hw_param_values),
                            'mean': sum(hw_param_values) / len(hw_param_values)
                        }
                        print(f"[DEBUG] ç¡¬ä»¶å‚æ•°åˆ†å¸ƒ(logç©ºé—´): min={hw_stats['min']:.6f}, max={hw_stats['max']:.6f}, mean={hw_stats['mean']:.6f}")
                        # å®‰å…¨æ ¼å¼åŒ–ç¡¬ä»¶å‚æ•°è¯¦æƒ…
                        pe_val = hw_param_details.get('log_num_pes', 'N/A')
                        l0_val = hw_param_details.get('log_l0_kb', 'N/A')
                        l1_val = hw_param_details.get('log_l1_kb', 'N/A')
                        l2_val = hw_param_details.get('log_l2_kb', 'N/A')
                        
                        pe_str = f"{pe_val:.6f}" if isinstance(pe_val, (int, float)) else str(pe_val)
                        l0_str = f"{l0_val:.6f}" if isinstance(l0_val, (int, float)) else str(l0_val)
                        l1_str = f"{l1_val:.6f}" if isinstance(l1_val, (int, float)) else str(l1_val)
                        l2_str = f"{l2_val:.6f}" if isinstance(l2_val, (int, float)) else str(l2_val)
                        
                        print(f"[DEBUG] ç¡¬ä»¶å‚æ•°è¯¦æƒ…: PE={pe_str}, L0={l0_str}, L1={l1_str}, L2={l2_str}")

                    # è®°å½•å†å²æ•°æ®ç”¨äºå¯è§†åŒ–
                    current_step = len(self.loss_history)
                    self.loss_history.append(loss.item())
                    self.grad_norm_history.append(hw_grad_norm)
                    self.step_history.append(current_step)
                    self.phase_history.append('B')
                    # è®°å½•ç¡¬ä»¶å‚æ•°çŠ¶æ€ç”¨äºçƒ­åŠ›å›¾
                    current_hw_snapshot = {'hardware': hw_stats} if hw_param_values else {}
                    if hw_param_details:
                        current_hw_snapshot['hardware_details'] = hw_param_details
                    self.param_history.append(current_hw_snapshot)

                    # ---- è°ƒè¯•æ—¥å¿—è®°å½•ï¼ˆPhase Bï¼‰ ----
                    if self.recorder is not None:
                        log_num_pes_grad = self.hw_params.log_num_pes.grad
                        l0_grad = self.hw_params.log_buffer_sizes_kb['L0_Registers'].grad
                        l1_grad = self.hw_params.log_buffer_sizes_kb['L1_Accumulator'].grad
                        l2_grad = self.hw_params.log_buffer_sizes_kb['L2_Scratchpad'].grad
                        debug_snapshot = {
                            "trial": trial_count + 1,
                            "phase": "B_Hardware",
                            "outer_step": outer_step,
                            "inner_step": i,
                            "loss": loss.item(),
                            "loss_breakdown": {
                                "log_edp": (torch.log(latency + 1e-9) + torch.log(energy + 1e-9)).item(),
                                "area_penalty": (self.loss_weights['area_weight'] * area).item(),
                                "mismatch_penalty": mismatch_loss.item(),
                                "compatibility_penalty": compatibility_penalty.item()
                            },
                            "learning_rate": self.lr_hardware,
                            "hardware_params_log_space": {
                                "log_num_pes": self.hw_params.log_num_pes.item(),
                                "log_l0_kb": self.hw_params.log_buffer_sizes_kb['L0_Registers'].item(),
                                "log_l1_kb": self.hw_params.log_buffer_sizes_kb['L1_Accumulator'].item(),
                                "log_l2_kb": self.hw_params.log_buffer_sizes_kb['L2_Scratchpad'].item()
                            },
                            "gradients": {
                                "log_num_pes_grad": float(log_num_pes_grad.item()) if log_num_pes_grad is not None else 0.0,
                                "log_l0_kb_grad": float(l0_grad.item()) if l0_grad is not None else 0.0,
                                "log_l1_kb_grad": float(l1_grad.item()) if l1_grad is not None else 0.0,
                                "log_l2_kb_grad": float(l2_grad.item()) if l2_grad is not None else 0.0
                            }
                        }
                        self.recorder.log_coopt_debug_step(debug_snapshot)

                    # è®°å½•ä¼˜åŒ–å‰çš„ç¡¬ä»¶å‚æ•°
                    hw_before_step = {
                        'num_pes': self.hw_params.get_projected_num_pes().item(),
                        'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                        'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                        'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                    }
                    
                    optimizer_hw.step()
                    
                    # è®°å½•ä¼˜åŒ–åçš„ç¡¬ä»¶å‚æ•°
                    hw_after_step = {
                        'num_pes': self.hw_params.get_projected_num_pes().item(),
                        'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                        'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                        'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                    }

                    # Enforce minimal hardware as lower bounds after the update
                    with torch.no_grad():
                        self._apply_min_hw_bounds(min_hw, reset=False)
                        
                        # è®°å½•åº”ç”¨çº¦æŸåçš„ç¡¬ä»¶å‚æ•°
                        hw_after_bounds = {
                            'num_pes': self.hw_params.get_projected_num_pes().item(),
                            'L0_size_kb': self.hw_params.get_buffer_size_kb('L0_Registers').item(),
                            'L1_size_kb': self.hw_params.get_buffer_size_kb('L1_Accumulator').item(),
                            'L2_size_kb': self.hw_params.get_buffer_size_kb('L2_Scratchpad').item()
                        }
                        
                        # æ¯æ­¥éƒ½æ‰“å°ç¡¬ä»¶é…ç½®ä¿¡æ¯ï¼ŒåŒ…æ‹¬EDP
                        edp_value = (latency * energy).item()
                        print(f"\n[HARDWARE] Outer Step {outer_step+1}, Inner Step {i+1}:")
                        print(f"[HARDWARE]   PEæ•°é‡: {hw_after_bounds['num_pes']:.0f}")
                        print(f"[HARDWARE]   L0ç¼“å­˜: {hw_after_bounds['L0_size_kb']:.2f} KB")
                        print(f"[HARDWARE]   L1ç¼“å­˜: {hw_after_bounds['L1_size_kb']:.2f} KB")
                        print(f"[HARDWARE]   L2ç¼“å­˜: {hw_after_bounds['L2_size_kb']:.2f} KB")
                        print(f"[HARDWARE]   æ€»é¢ç§¯: {area.item():.2f} mmÂ²")
                        print(f"[HARDWARE]   EDP: {edp_value:.2e} (å»¶è¿Ÿ: {latency.item():.2e}s, èƒ½è€—: {energy.item():.2e}pJ)")
                        
                        # æ¯10æ­¥æ‰“å°ä¸€æ¬¡è¯¦ç»†çš„lossç»„æˆéƒ¨åˆ†
                        if i % 10 == 0:
                            # è®¡ç®—å¹¶æ˜¾ç¤ºlossçš„è¯¦ç»†ç»„æˆéƒ¨åˆ†
                            comp_penalty_weight = self.loss_weights.get('compatibility_penalty_weight', 100.0)
                            comp_penalty = comp_penalty_weight * compatibility_penalty
                            
                            if self.loss_strategy == 'strategy_A':
                                edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                                area_loss = self.loss_weights['area_weight'] * area
                                mismatch_penalty = torch.log(1.0 + mismatch_loss * self.loss_weights['mismatch_penalty_weight'])
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (strategy_A): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - Log(EDP): {edp_loss.item():.6f}")
                                print(f"[DEBUG]   - Areaæƒ©ç½š: {area_loss.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                                
                            elif self.loss_strategy == 'strategy_B':
                                edp_loss = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                                area_loss = self.loss_weights['area_weight'] * area
                                mismatch_penalty = mismatch_loss * self.loss_weights['mismatch_penalty_weight']
                                weighted_edp = self.loss_weights['edp_weight'] * edp_loss
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (strategy_B): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - åŠ æƒLog(EDP): {weighted_edp.item():.6f}")
                                print(f"[DEBUG]   - Areaæƒ©ç½š: {area_loss.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                                
                            elif self.loss_strategy == 'log_edp_plus_area':
                                log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                                area_penalty = self.loss_weights['area_weight'] * area
                                mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (log_edp_plus_area): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - Log(EDP): {log_edp.item():.6f}")
                                print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                                
                            elif self.loss_strategy == 'edp_plus_area':
                                edp = latency * energy
                                area_penalty = self.loss_weights['area_weight'] * area
                                mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (edp_plus_area): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - EDP: {edp.item():.6f}")
                                print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                                
                            elif self.loss_strategy == 'pure_edp':
                                edp = latency * energy
                                mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                                area_budget_penalty = self._compute_area_budget_penalty(area, i)
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (pure_edp): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - EDP: {edp.item():.6f}")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                                print(f"[DEBUG]   - é¢ç§¯é¢„ç®—æƒ©ç½š: {area_budget_penalty.item():.6f}")
                                print(f"[DEBUG]   - é¢ç§¯: {area.item():.2f} mmÂ² (åŸºç¡€é¢ç§¯ï¼Œé¢„ç®—æƒ©ç½šå·²å•ç‹¬è®¡ç®—)")
                                
                            else:
                                # é»˜è®¤ç­–ç•¥
                                log_edp = torch.log(latency + 1e-9) + torch.log(energy + 1e-9)
                                area_penalty = self.loss_weights['area_weight'] * area
                                mismatch_penalty = mismatch_loss * self.loss_weights.get('mismatch_penalty_weight', 0.1)
                                print(f"[DEBUG] Lossè¯¦ç»†ç»„æˆ (é»˜è®¤ç­–ç•¥): æ€»è®¡={loss.item():.6f}")
                                print(f"[DEBUG]   - Log(EDP): {log_edp.item():.6f}")
                                print(f"[DEBUG]   - Areaæƒ©ç½š: {area_penalty.item():.6f} (é¢ç§¯: {area.item():.2f} mmÂ²)")
                                print(f"[DEBUG]   - Mismatchæƒ©ç½š: {mismatch_penalty.item():.6f}")
                                print(f"[DEBUG]   - Compatibilityæƒ©ç½š: {comp_penalty.item():.6f}")
                            
                            # æ˜¾ç¤ºåŸºç¡€æ€§èƒ½æŒ‡æ ‡
                            print(f"[DEBUG] åŸºç¡€æŒ‡æ ‡: å»¶è¿Ÿ={latency.item():.2e}s, èƒ½è€—={energy.item():.2e}pJ")
                            
                            # æ£€æŸ¥optimizer.step()é€ æˆçš„å˜åŒ–
                            step_changes = []
                            for key in hw_before_step:
                                if abs(hw_before_step[key] - hw_after_step[key]) > 1e-6:
                                    step_changes.append(f"{key}: {hw_before_step[key]:.2f} -> {hw_after_step[key]:.2f}")
                            
                            if step_changes:
                                print(f"[DEBUG] Optimizeræ­¥éª¤å˜åŒ–: {', '.join(step_changes)}")
                            
                            # æ£€æŸ¥åº”ç”¨æœ€å°ç¡¬ä»¶çº¦æŸé€ æˆçš„å˜åŒ–
                            bounds_changes = []
                            for key in hw_after_step:
                                if abs(hw_after_step[key] - hw_after_bounds[key]) > 1e-6:
                                    bounds_changes.append(f"{key}: {hw_after_step[key]:.2f} -> {hw_after_bounds[key]:.2f}")
                            
                            if bounds_changes:
                                print(f"[DEBUG] æœ€å°çº¦æŸè°ƒæ•´: {', '.join(bounds_changes)}")
                            
                            if not step_changes and not bounds_changes:
                                print(f"[DEBUG] âœ“ ç¡¬ä»¶å‚æ•°æ— å˜åŒ–")

                    # è®¡ç®—æŒ‡æ ‡ç”¨äºè®°å½•ï¼ˆé¿å…å†æ¬¡è°ƒç”¨ evaluate(flat_params) é€ æˆçš„äºŒæ¬¡å®Œæ•´å‰å‘ï¼‰
                    with torch.no_grad():
                        current_params = self._get_params_as_dict()
                        latency2, energy2, area2, mismatch2, compat2 = self.perf_model(
                            self.graph, self.hw_params, self.mapping, self.fusion_params
                        )
                        metrics = {
                            'latency_sec': latency2.item(),
                            'energy_pj': energy2.item(),
                            'area_mm2': area2.item(),
                            'edp': (latency2 * energy2).item(),
                            'log_edp': (torch.log(latency2 + 1e-9) + torch.log(energy2 + 1e-9)).item(),
                            'mismatch_loss': mismatch2.item()
                        }
                    
                    # åœ¨æ¯ä¸ªhardware stepä¸­æ£€æŸ¥å¹¶æ›´æ–°æœ€ä½³ç»“æœ
                    trial_count += 1
                    old_best_loss = self.best_loss
                    self.update_best_result(loss.item(), current_params, metrics, trial_count)
                    
                    # è´¨é‡é©±åŠ¨çš„è§¦å‘ï¼šå½“æ‰¾åˆ°æ–°çš„å…¨å±€æœ€ä¼˜è§£æ—¶ä¿å­˜é…ç½®
                    if loss.item() < old_best_loss:
                        self._save_validation_config(trial_count, "quality_driven")
                    
                    # æ·»åŠ è¿›åº¦è¾“å‡º
                    if i % 2 == 0 or i == self.num_hardware_steps - 1:
                        if self.logger:
                            self.logger.console(
                                f"  Hardware Step {i+1}/{self.num_hardware_steps}: Loss={loss.item():.4f}, EDP={metrics['edp']:.2e}, Area={metrics['area_mm2']:.2f}mmÂ²"
                            )
                
                # Disable Phase-B freeze and restore train
                self._freeze_discrete = False
                try:
                    self.mapping.train()
                    self.fusion_params.train()
                except Exception:
                    pass

                # Phase Bç»“æŸåçš„æœ€ç»ˆè®°å½•ï¼ˆæœ€ä½³ç»“æœå·²åœ¨æ¯ä¸ªhardware stepä¸­æ›´æ–°ï¼‰
                # è®°å½•æ—¥å¿—
                if self.num_hardware_steps % 10 == 0:
                    self.log_trial(trial_count, loss.item(), metrics, current_params)
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.generate_all_visualizations()
        
        return {
            'best_loss': self.best_loss,
            'best_params': self.best_params,
            'best_metrics': self.best_metrics,
            'best_edp': self.best_edp,
            'best_edp_params': self.best_edp_params,
            'best_edp_metrics': self.best_edp_metrics,
            'total_trials': trial_count
        }
    
    def _save_validation_config(self, trial_count: int, trigger_type: str):
        """
        ä¿å­˜å½“å‰é…ç½®åˆ°éªŒè¯æ•°æ®é›†
        
        Args:
            trial_count: å½“å‰è¯•éªŒæ¬¡æ•°
            trigger_type: è§¦å‘ç±»å‹ï¼ˆ"quality_driven" æˆ– "diversity_driven"ï¼‰
        """
        from .utils import save_configuration_to_json
        
        try:
            # è·å–å½“å‰å®Œæ•´çš„æ˜ å°„ä¿¡æ¯
            projected_mapping = self.mapping.get_all_factors()
            
            # è·å–èåˆå†³ç­–
            fusion_decisions = self.fusion_params.get_fusion_decisions_serializable(self.graph)
            
            # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
            file_path = f"output/validation_config_trial_{trial_count}.json"
            
            # ä¿å­˜é…ç½®
            save_configuration_to_json(
                hw_params=self.hw_params,
                projected_mapping=projected_mapping,
                fusion_decisions=fusion_decisions,
                file_path=file_path
            )
            
            if self.logger:
                self.logger.event("validation_config_saved", trigger=trigger_type, file_path=file_path)
            
        except Exception as e:
            print(f"Warning: Failed to save validation config at trial {trial_count}: {e}")
    
    def plot_convergence_curves(self, save_path='output/convergence_curves.png'):
        """
        ç»˜åˆ¶æ”¶æ•›æ›²çº¿ï¼ˆloss vs stepï¼‰å’Œæ¢¯åº¦èŒƒæ•°æ›²çº¿
        
        Args:
            save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„
        """
        import matplotlib.pyplot as plt
        import os
        
        if not self.loss_history or not self.grad_norm_history:
            print("Warning: No history data available for plotting")
            return
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # åˆ›å»ºå­å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # ç»˜åˆ¶lossæ”¶æ•›æ›²çº¿
        ax1.plot(self.step_history, self.loss_history, 'b-', linewidth=2, label='Loss')
        ax1.set_xlabel('Step')
        ax1.set_ylabel('Loss')
        ax1.set_title('Loss Convergence Curve')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # æ ‡è®°Phase Aå’ŒPhase Bçš„åˆ†ç•Œç‚¹
        phase_changes = []
        for i in range(1, len(self.phase_history)):
            if self.phase_history[i] != self.phase_history[i-1]:
                phase_changes.append(self.step_history[i])
        
        for change_step in phase_changes:
            ax1.axvline(x=change_step, color='red', linestyle='--', alpha=0.7, label='Phase Change')
        
        # ç»˜åˆ¶æ¢¯åº¦èŒƒæ•°æ›²çº¿
        ax2.plot(self.step_history, self.grad_norm_history, 'g-', linewidth=2, label='Gradient Norm')
        ax2.set_xlabel('Step')
        ax2.set_ylabel('Gradient Norm')
        ax2.set_title('Gradient Norm vs Step')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        # æ ‡è®°Phaseå˜åŒ–
        for change_step in phase_changes:
            ax2.axvline(x=change_step, color='red', linestyle='--', alpha=0.7)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Convergence curves saved to: {save_path}")
    
    def plot_parameter_heatmap(self, save_path='output/parameter_heatmap.png'):
        """
        ç»˜åˆ¶å‚æ•°çƒ­åŠ›å›¾ï¼Œæ˜¾ç¤ºæœç´¢è¶‹åŠ¿
        
        Args:
            save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„
        """
        import matplotlib.pyplot as plt
        import numpy as np
        import os
        
        if not self.param_history:
            print("Warning: No parameter history available for heatmap")
            return
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # æå–å‚æ•°åç§°å’Œå€¼
        param_names = list(self.param_history[0].keys()) if self.param_history else []
        if not param_names:
            print("Warning: No parameters found in history")
            return
        
        # æ„å»ºå‚æ•°çŸ©é˜µ (steps x parameters)
        param_matrix = []
        for step_params in self.param_history:
            row = []
            for param_name in param_names:
                value = step_params.get(param_name, 0.0)
                # å¦‚æœæ˜¯tensorï¼Œè½¬æ¢ä¸ºæ ‡é‡
                if hasattr(value, 'item'):
                    value = value.item()
                row.append(float(value))
            param_matrix.append(row)
        
        param_matrix = np.array(param_matrix)
        
        # å½’ä¸€åŒ–å‚æ•°å€¼åˆ°[0,1]èŒƒå›´ä»¥ä¾¿å¯è§†åŒ–
        param_matrix_norm = np.zeros_like(param_matrix)
        for i in range(param_matrix.shape[1]):
            col = param_matrix[:, i]
            if col.max() != col.min():
                param_matrix_norm[:, i] = (col - col.min()) / (col.max() - col.min())
            else:
                param_matrix_norm[:, i] = 0.5  # å¦‚æœæ‰€æœ‰å€¼ç›¸åŒï¼Œè®¾ä¸ºä¸­é—´å€¼
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(max(12, len(param_names) * 0.8), 8))
        
        im = ax.imshow(param_matrix_norm.T, cmap='viridis', aspect='auto', interpolation='nearest')
        
        # è®¾ç½®åæ ‡è½´
        ax.set_xlabel('Optimization Step')
        ax.set_ylabel('Parameters')
        ax.set_title('Parameter Evolution Heatmap (Normalized Values)')
        
        # è®¾ç½®yè½´æ ‡ç­¾
        ax.set_yticks(range(len(param_names)))
        ax.set_yticklabels([name.replace('_', '\n') for name in param_names], fontsize=8)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label('Normalized Parameter Value', rotation=270, labelpad=15)
        
        # æ ‡è®°Phaseå˜åŒ–
        phase_changes = []
        for i in range(1, len(self.phase_history)):
            if self.phase_history[i] != self.phase_history[i-1]:
                phase_changes.append(i)
        
        for change_step in phase_changes:
            ax.axvline(x=change_step, color='red', linestyle='--', alpha=0.7, linewidth=2)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Parameter heatmap saved to: {save_path}")
    
    def generate_all_visualizations(self, output_dir='output'):
        """
        ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        import os
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print("\n=== ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ===")
        
        # ç”Ÿæˆæ”¶æ•›æ›²çº¿
        convergence_path = os.path.join(output_dir, 'convergence_curves.png')
        self.plot_convergence_curves(convergence_path)
        
        # ç”Ÿæˆå‚æ•°çƒ­åŠ›å›¾
        heatmap_path = os.path.join(output_dir, 'parameter_heatmap.png')
        self.plot_parameter_heatmap(heatmap_path)
        
        print(f"All visualizations saved to: {output_dir}")


class RandomSearcher(BaseSearcher):
    """
    éšæœºæœç´¢å™¨ï¼šéšæœºé‡‡æ ·å‚æ•°ç©ºé—´
    """
    
    def __init__(self, graph, hw_params, mapping, fusion_params, perf_model, config, logger=None):
        super().__init__(graph, hw_params, mapping, fusion_params, perf_model, config, logger)
    
    def search(self, num_trials: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œéšæœºæœç´¢
        
        Args:
            num_trials: éšæœºè¯•éªŒæ¬¡æ•°
            
        Returns:
            æœ€ä½³ç»“æœå­—å…¸
        """
        print(f"Starting Random Search with {num_trials} trials...")
        
        for trial in range(num_trials):
            # ä½¿ç”¨SearchSpaceéšæœºé‡‡æ ·å‚æ•°
            random_params_dict = self.space.sample()
            
            # è½¬æ¢ä¸ºæ‰å¹³åŒ–æ ¼å¼
            flat_params = self.space.to_flat(random_params_dict)
            
            # è¯„ä¼°å½“å‰é…ç½®
            loss, metrics = self.evaluate(flat_params)
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            self.update_best_result(loss, random_params_dict, metrics, trial + 1)
            
            # è®°å½•æ—¥å¿—
            if (trial + 1) % 10 == 0 or trial == 0:
                best_edp = self.best_edp_metrics['edp'] if self.best_edp_metrics else float('inf')
                print(f"Trial {trial + 1}: Loss={loss:.4f}, EDP={metrics['edp']:.2e}, Best EDP={best_edp:.2e}")
            
            self.log_trial(trial + 1, loss, metrics, random_params_dict)
        
        return {
            'best_loss': self.best_loss,
            'best_params': self.best_params,
            'best_metrics': self.best_metrics,
            'best_edp': self.best_edp,
            'best_edp_params': self.best_edp_params,
            'best_edp_metrics': self.best_edp_metrics,
            'total_trials': num_trials
        }


class BayesianOptimizationSearcher(BaseSearcher):
    """
    è´å¶æ–¯ä¼˜åŒ–æœç´¢å™¨ï¼šåŸºäº scikit-optimize çš„é«˜æ•ˆé»‘ç›’ä¼˜åŒ–
    """
    
    def __init__(self, graph, hw_params, mapping, fusion_params, perf_model, config, logger=None):
        super().__init__(graph, hw_params, mapping, fusion_params, perf_model, config, logger)
        
        # å®šä¹‰ scikit-optimize æœç´¢ç©ºé—´
        self.skopt_space = self._define_search_space()
    
    def _define_search_space(self):
        """
        å°† SearchSpace è½¬æ¢ä¸º scikit-optimize æ ¼å¼çš„æœç´¢ç©ºé—´
        
        Returns:
            scikit-optimize çš„ space å¯¹è±¡åˆ—è¡¨
        """
        from skopt.space import Real, Integer, Categorical
        
        skopt_dimensions = []
        
        # éå† SearchSpace ä¸­å®šä¹‰çš„æ‰€æœ‰ç»´åº¦ï¼Œç¡®ä¿é¡ºåºä¸€è‡´
        for dim in self.space.dimensions:
            dim_type = dim['type']
            name = dim['name']
            
            if dim_type == 'integer_square':
                # å¹³æ–¹æ•°å‚æ•°ï¼šä½¿ç”¨sqrtèŒƒå›´
                min_sqrt, max_sqrt = dim['range']
                skopt_dimensions.append(
                    Integer(low=min_sqrt, high=max_sqrt, name=name)
                )
            
            elif dim_type == 'log_uniform':
                # å¯¹æ•°å‡åŒ€åˆ†å¸ƒ
                min_val, max_val = dim['range']
                skopt_dimensions.append(
                    Real(low=min_val, high=max_val, 
                         prior='log-uniform', name=name)
                )
            
            elif dim_type == 'categorical':
                # ç±»åˆ«ç±»å‹å‚æ•°ï¼šä½¿ç”¨Categoricalç»´åº¦
                categories = dim['categories']
                skopt_dimensions.append(
                    Categorical(categories=categories, name=name)
                )
            
            else:
                raise ValueError(f"Unknown dimension type: {dim_type}")
        
        return skopt_dimensions
    
    def search(self, num_trials: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–æœç´¢
        
        Args:
            num_trials: è¯„ä¼°æ¬¡æ•°
            
        Returns:
            æœ€ä½³ç»“æœå­—å…¸
        """
        from skopt import gp_minimize
        
        print(f"Starting Bayesian Optimization with {num_trials} trials...")
        
        # å®šä¹‰ç›®æ ‡å‡½æ•°
        def objective(flat_params: list) -> float:
            """
            è´å¶æ–¯ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°
            
            Args:
                flat_params: scikit-optimize ä¼ å…¥çš„æ‰å¹³åŒ–å‚æ•°åˆ—è¡¨
                
            Returns:
                æŸå¤±å€¼ï¼ˆéœ€è¦æœ€å°åŒ–ï¼‰
            """
            # è¯„ä¼°å‚æ•°é…ç½®
            loss, metrics = self.evaluate(flat_params)
            
            # å¤„ç†æ— æ•ˆçš„æŸå¤±å€¼
            import numpy as np
            if np.isnan(loss) or np.isinf(loss) or loss > 1e15:
                # å¯¹äºæ— æ•ˆå€¼ï¼Œä½¿ç”¨ä¸€ä¸ªå¤§çš„æœ‰é™å€¼
                loss = 1e15
                # åŒæ—¶ä¿®æ­£metricsä¸­çš„æ— æ•ˆå€¼
                for key, value in metrics.items():
                    if np.isnan(value) or np.isinf(value):
                        metrics[key] = 1e15
            
            # å°†æ‰å¹³åŒ–å‚æ•°è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸ç”¨äºè®°å½•
            params_dict = self.space.from_flat(flat_params)
            
            # æ›´æ–°æœ€ä½³ç»“æœï¼ˆåªæœ‰å½“æŸå¤±å€¼æœ‰æ•ˆæ—¶ï¼‰
            trial_num = len(objective.trial_history) + 1
            if loss < 1e15:  # åªæœ‰æœ‰æ•ˆçš„æŸå¤±å€¼æ‰æ›´æ–°æœ€ä½³ç»“æœ
                loss_breakdown = getattr(self, '_last_loss_breakdown', None)
                self.update_best_result(loss, params_dict, metrics, trial_num, loss_breakdown)
            
            # è®°å½•è¯•éªŒå†å²
            objective.trial_history.append({
                'loss': loss,
                'metrics': metrics,
                'params': params_dict
            })
            
            # è®°å½•æ—¥å¿—
            if trial_num % 10 == 0 or trial_num == 1:
                best_edp = self.best_metrics['edp'] if self.best_metrics else float('inf')
                print(f"BO Trial {trial_num}: Loss={loss:.4f}, EDP={metrics['edp']:.2e}, Best EDP={best_edp:.2e}")
            
            self.log_trial(trial_num, loss, metrics, params_dict)
            
            return loss
        
        # åˆå§‹åŒ–è¯•éªŒå†å²
        objective.trial_history = []
        
        # æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
        result = gp_minimize(
            func=objective,
            dimensions=self.skopt_space,
            n_calls=num_trials,
            n_initial_points=min(20, num_trials // 2),  # åˆå§‹éšæœºé‡‡æ ·ç‚¹æ•°
            random_state=42,  # å›ºå®šéšæœºç§å­ä¿è¯å¯å¤ç°æ€§
            acq_func='EI',  # æœŸæœ›æ”¹è¿›é‡‡é›†å‡½æ•°
            n_jobs=1  # å•çº¿ç¨‹æ‰§è¡Œ
        )
        
        # å¤„ç†ä¼˜åŒ–ç»“æœ
        best_flat_params = result.x
        best_loss = result.fun
        
        # å°†æœ€ä¼˜å‚æ•°è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸
        best_params_dict = self.space.from_flat(best_flat_params)
        
        print(f"\nBayesian Optimization completed!")
        print(f"Best loss: {best_loss:.4f}")
        if self.best_edp_metrics is not None:
            print(f"Best EDP: {self.best_edp_metrics['edp']:.2e}")
        else:
            print("No valid solutions found during optimization.")

        return {
            'best_loss': self.best_loss,
            'best_params': self.best_params,
            'best_metrics': self.best_metrics or {},  # å¦‚æœä¸ºNoneåˆ™è¿”å›ç©ºå­—å…¸
            'best_edp': self.best_edp,
            'best_edp_params': self.best_edp_params,
            'best_edp_metrics': self.best_edp_metrics or {},
            'total_trials': num_trials,
            'skopt_result': result  # ä¿å­˜å®Œæ•´çš„ scikit-optimize ç»“æœ
        }


class GeneticAlgorithmSearcher(BaseSearcher):
    """
    é—ä¼ ç®—æ³•æœç´¢å™¨ï¼ˆåŸºäºDEAPå®ç°ï¼‰
    """
    
    def __init__(self, graph, hw_params, mapping, fusion_params, perf_model, config, logger=None):
        super().__init__(graph, hw_params, mapping, fusion_params, perf_model, config, logger)
        
        # é—ä¼ ç®—æ³•å‚æ•°
        self.population_size = getattr(config, 'GA_POPULATION_SIZE', 50)
        self.mutation_rate = getattr(config, 'GA_MUTATION_RATE', 0.1)
        self.crossover_rate = getattr(config, 'GA_CROSSOVER_RATE', 0.8)
        
        # åˆå§‹åŒ–DEAP
        self._setup_deap()
    
    def _setup_deap(self):
        """
        è®¾ç½®DEAPé—ä¼ ç®—æ³•æ¡†æ¶
        """
        from deap import base, creator, tools
        
        # åˆ›å»ºé€‚åº”åº¦ç±»å‹ï¼ˆæœ€å°åŒ–ï¼‰
        if not hasattr(creator, "FitnessMin"):
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
        
        # åˆ›å»ºä¸ªä½“ç±»å‹
        if not hasattr(creator, "Individual"):
            creator.create("Individual", list, fitness=creator.FitnessMin)
        
        # åˆ›å»ºå·¥å…·ç®±
        self.toolbox = base.Toolbox()
        
        # æ³¨å†ŒåŸºå› ç”Ÿæˆå‡½æ•°
        self.toolbox.register("attr_item", self._sample_attribute)
        
        # æ³¨å†Œä¸ªä½“å’Œç§ç¾¤ç”Ÿæˆå‡½æ•°
        self.toolbox.register("individual", tools.initIterate, creator.Individual, self.toolbox.attr_item)
        self.toolbox.register("population", tools.initRepeat, list, self.toolbox.individual)
        
        # æ³¨å†Œæ¼”åŒ–ç®—å­
        self.toolbox.register("evaluate", self._deap_evaluate_wrapper)
        self.toolbox.register("mate", tools.cxTwoPoint)
        self.toolbox.register("mutate", self._deap_mutate, indpb=self.mutation_rate)
        self.toolbox.register("select", tools.selTournament, tournsize=3)
    
    def _sample_attribute(self) -> list:
        """
        ä»æœç´¢ç©ºé—´ä¸­éšæœºé‡‡æ ·ä¸€ä¸ªæ‰å¹³åŒ–çš„å‚æ•°åˆ—è¡¨
        
        Returns:
            æ‰å¹³åŒ–çš„å‚æ•°åˆ—è¡¨
        """
        # ä»SearchSpaceéšæœºé‡‡æ ·
        params_dict = self.space.sample()
        # è½¬æ¢ä¸ºæ‰å¹³åŒ–åˆ—è¡¨
        return self.space.to_flat(params_dict)
    
    def _deap_evaluate_wrapper(self, individual: list) -> tuple:
        """
        DEAPè¯„ä¼°å‡½æ•°åŒ…è£…å™¨
        
        Args:
            individual: ä¸ªä½“ï¼ˆæ‰å¹³åŒ–å‚æ•°åˆ—è¡¨ï¼‰
            
        Returns:
            é€‚åº”åº¦å…ƒç»„
        """
        # è¯„ä¼°ä¸ªä½“
        loss, metrics = self.evaluate(individual)
        
        # è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸ç”¨äºè®°å½•
        params_dict = self.space.from_flat(individual)
        
        # æ›´æ–°æœ€ä½³ç»“æœ
        trial_num = getattr(self, '_current_trial', 0) + 1
        self._current_trial = trial_num
        loss_breakdown = getattr(self, '_last_loss_breakdown', None)
        self.update_best_result(loss, params_dict, metrics, trial_num, loss_breakdown)
        
        # è®°å½•æ—¥å¿—
        if trial_num % 10 == 0 or trial_num == 1:
            best_edp = self.best_metrics['edp'] if self.best_metrics else float('inf')
            print(f"GA Trial {trial_num}: Loss={loss:.4f}, EDP={metrics['edp']:.2e}, Best EDP={best_edp:.2e}")
        
        self.log_trial(trial_num, loss, metrics, params_dict)
        
        # DEAPéœ€è¦è¿”å›å…ƒç»„
        return (loss,)
    
    def _deap_mutate(self, individual: list, indpb: float) -> tuple:
        """
        è‡ªå®šä¹‰å˜å¼‚ç®—å­
        
        Args:
            individual: ä¸ªä½“ï¼ˆæ‰å¹³åŒ–å‚æ•°åˆ—è¡¨ï¼‰
            indpb: æ¯ä¸ªåŸºå› çš„å˜å¼‚æ¦‚ç‡
            
        Returns:
            å˜å¼‚åçš„ä¸ªä½“
        """
        import random
        
        # éå†ä¸ªä½“ä¸­çš„æ¯ä¸ªåŸºå› 
        for i in range(len(individual)):
            # ä»¥indpbæ¦‚ç‡å†³å®šæ˜¯å¦å˜å¼‚
            if random.random() < indpb:
                # è·å–å¯¹åº”çš„ç»´åº¦å®šä¹‰
                dim = self.space.dimensions[i]
                dim_type = dim['type']
                
                if dim_type == 'integer_square':
                    # å¹³æ–¹æ•°å‚æ•°ï¼šé‡æ–°é‡‡æ ·sqrtå€¼
                    min_sqrt, max_sqrt = dim['range']
                    individual[i] = float(random.randint(min_sqrt, max_sqrt))
                    
                elif dim_type == 'log_uniform':
                    # å¯¹æ•°å‡åŒ€åˆ†å¸ƒï¼šé‡æ–°é‡‡æ ·
                    min_val, max_val = dim['range']
                    import numpy as np
                    log_min, log_max = np.log(min_val), np.log(max_val)
                    individual[i] = float(np.exp(random.uniform(log_min, log_max)))
                    
                elif dim_type == 'categorical':
                    # ç±»åˆ«å‚æ•°ï¼šé‡æ–°é‡‡æ ·ç´¢å¼•
                    num_categories = len(dim['categories'])
                    individual[i] = float(random.randint(0, num_categories - 1))
                    
                else:
                    raise ValueError(f"Unknown dimension type: {dim_type}")
        
        return (individual,)
    
    def search(self, num_trials: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œé—ä¼ ç®—æ³•æœç´¢
        
        Args:
            num_trials: è¯„ä¼°æ¬¡æ•°ï¼ˆå¯¹åº”äºä»£æ•° * ç§ç¾¤å¤§å°ï¼‰
            
        Returns:
            æœ€ä½³ç»“æœå­—å…¸
        """
        from deap import algorithms, tools
        import random
        
        # è®¡ç®—ä»£æ•°
        generations = max(1, num_trials // self.population_size)
        actual_trials = generations * self.population_size
        
        print(f"Starting Genetic Algorithm with {generations} generations, population size {self.population_size}")
        print(f"Total evaluations: {actual_trials}")
        
        # åˆå§‹åŒ–è¯•éªŒè®¡æ•°å™¨
        self._current_trial = 0
        
        # è®¾ç½®éšæœºç§å­
        random.seed(42)
        
        # åˆå§‹åŒ–ç§ç¾¤
        pop = self.toolbox.population(n=self.population_size)
        
        # è®¾ç½®ç»Ÿè®¡ä¿¡æ¯
        stats = tools.Statistics(lambda ind: ind.fitness.values[0])
        stats.register("avg", lambda x: sum(x) / len(x))
        stats.register("min", min)
        stats.register("max", max)
        
        # åäººå ‚ï¼ˆä¿å­˜æœ€ä¼˜ä¸ªä½“ï¼‰
        hof = tools.HallOfFame(1)
        
        # è¿è¡Œæ¼”åŒ–ç®—æ³•
        print("\nStarting evolution...")
        
        # è¯„ä¼°åˆå§‹ç§ç¾¤
        fitnesses = list(map(self.toolbox.evaluate, pop))
        for ind, fit in zip(pop, fitnesses):
            ind.fitness.values = fit
        
        # æ›´æ–°åäººå ‚
        hof.update(pop)
        
        # è®°å½•åˆå§‹ç»Ÿè®¡ä¿¡æ¯
        record = stats.compile(pop)
        print(f"Generation 0: {record}")
        
        # æ¼”åŒ–å¾ªç¯
        for generation in range(1, generations + 1):
            print(f"\n--- Generation {generation}/{generations} ---")
            
            # é€‰æ‹©ä¸‹ä¸€ä»£çš„çˆ¶ä»£
            offspring = self.toolbox.select(pop, len(pop))
            offspring = list(map(self.toolbox.clone, offspring))
            
            # äº¤å‰
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < self.crossover_rate:
                    self.toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            
            # å˜å¼‚
            for mutant in offspring:
                if random.random() < self.mutation_rate:
                    self.toolbox.mutate(mutant)
                    del mutant.fitness.values
            
            # è¯„ä¼°æ— æ•ˆä¸ªä½“
            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            fitnesses = list(map(self.toolbox.evaluate, invalid_ind))
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit
            
            # æ›¿æ¢ç§ç¾¤
            pop[:] = offspring
            
            # æ›´æ–°åäººå ‚
            hof.update(pop)
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            record = stats.compile(pop)
            print(f"Generation {generation}: {record}")
        
        # è·å–æœ€ä¼˜ä¸ªä½“
        best_individual = hof[0]
        best_loss = best_individual.fitness.values[0]
        
        # è½¬æ¢æœ€ä¼˜å‚æ•°ä¸ºç»“æ„åŒ–å­—å…¸
        best_params_dict = self.space.from_flat(list(best_individual))
        
        print(f"\nGenetic Algorithm completed!")
        print(f"Best loss: {best_loss:.4f}")
        if self.best_edp_metrics is not None:
            print(f"Best EDP: {self.best_edp_metrics['edp']:.2e}")
        print(f"Total evaluations: {self._current_trial}")

        return {
            'best_loss': self.best_loss,
            'best_params': self.best_params,
            'best_metrics': self.best_metrics,
            'best_edp': self.best_edp,
            'best_edp_params': self.best_edp_params,
            'best_edp_metrics': self.best_edp_metrics,
            'total_trials': self._current_trial,
            'generations': generations,
            'population_size': self.population_size,
            'hall_of_fame': hof  # ä¿å­˜åäººå ‚
        }